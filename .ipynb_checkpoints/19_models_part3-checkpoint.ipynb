{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELLING PART 3**\n",
    "\n",
    "- We have tried various algorithms from Sklearn, it's also worth trying a multi layer perceptron to see if we can improve our scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transaction dataframe\n",
    "\n",
    "latest_df = pd.read_csv('../../../big_files/latest_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features to be modelled\n",
    "\n",
    "updated_features = ['prop_type', 'fsm_lsoa', 'ea_in_ward', 'avg_airbnb', 'airbnb_tot', 'crime_lsoa', 'deli_count', 'flor_count', 'rest_count', 'income_rank_pos','employment_rank_pos', 'education_rank_pos', 'health_dep_score', 'crime_rank_pos', 'housing_rank_pos', 'living_env_pos', 'zone_50m','zone_200m', 'zone_400m', 'zone_800m', 'zone_1600m', 'zone_2400m', 'dist_traf', 'gang_prob_pos', 'crime_worry_pos', 'safety_fears_pos', 'satisfaction_pos', 'gun_crime', 'knife_crime', 'good_school', 'tube_zone', 'any_tube']\n",
    "\n",
    "updated_df = latest_df[updated_features]\n",
    "updated_df['price'] = latest_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-72f4b6558e99>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  updated_df['price'] = latest_df['price']\n"
     ]
    }
   ],
   "source": [
    "#prepare data for modelling\n",
    "\n",
    "y = updated_df.pop('price')\n",
    "X = updated_df\n",
    "\n",
    "# encode categorical columns\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns, index = y_train.index)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns, index = y_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mse as metric for MLP, the numbers are likely to be very big\n",
    "# divide by 100, then multiply out again for final predictions\n",
    "\n",
    "y_train_new = y_train / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate MLP\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 7s - loss: 84250080.0000 - mse: 84250080.0000 - val_loss: 67032368.0000 - val_mse: 67032368.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 7s - loss: 76276912.0000 - mse: 76276912.0000 - val_loss: 65242780.0000 - val_mse: 65242780.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 7s - loss: 74188152.0000 - mse: 74188152.0000 - val_loss: 63173368.0000 - val_mse: 63173368.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 7s - loss: 72713752.0000 - mse: 72713752.0000 - val_loss: 63788872.0000 - val_mse: 63788872.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 7s - loss: 71735432.0000 - mse: 71735432.0000 - val_loss: 62683384.0000 - val_mse: 62683384.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 7s - loss: 71334248.0000 - mse: 71334248.0000 - val_loss: 62347732.0000 - val_mse: 62347732.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 7s - loss: 70979136.0000 - mse: 70979136.0000 - val_loss: 62362660.0000 - val_mse: 62362660.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 7s - loss: 70973816.0000 - mse: 70973816.0000 - val_loss: 61038220.0000 - val_mse: 61038220.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 7s - loss: 70633736.0000 - mse: 70633736.0000 - val_loss: 61597572.0000 - val_mse: 61597572.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 7s - loss: 70492480.0000 - mse: 70492480.0000 - val_loss: 61843336.0000 - val_mse: 61843336.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 7s - loss: 70253568.0000 - mse: 70253568.0000 - val_loss: 62567816.0000 - val_mse: 62567816.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 7s - loss: 69775632.0000 - mse: 69775632.0000 - val_loss: 62553648.0000 - val_mse: 62553648.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 7s - loss: 70033624.0000 - mse: 70033624.0000 - val_loss: 60445844.0000 - val_mse: 60445844.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 7s - loss: 70081624.0000 - mse: 70081624.0000 - val_loss: 62544504.0000 - val_mse: 62544504.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 6s - loss: 69875688.0000 - mse: 69875688.0000 - val_loss: 61769216.0000 - val_mse: 61769216.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 7s - loss: 69283504.0000 - mse: 69283504.0000 - val_loss: 61567096.0000 - val_mse: 61567096.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 7s - loss: 69137136.0000 - mse: 69137136.0000 - val_loss: 61953004.0000 - val_mse: 61953004.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 7s - loss: 69205360.0000 - mse: 69205360.0000 - val_loss: 62259116.0000 - val_mse: 62259116.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 7s - loss: 68792288.0000 - mse: 68792288.0000 - val_loss: 62852496.0000 - val_mse: 62852496.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 7s - loss: 68974416.0000 - mse: 68974416.0000 - val_loss: 62379504.0000 - val_mse: 62379504.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 6s - loss: 69184176.0000 - mse: 69184176.0000 - val_loss: 62360032.0000 - val_mse: 62360032.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 7s - loss: 68699976.0000 - mse: 68699976.0000 - val_loss: 60931480.0000 - val_mse: 60931480.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 7s - loss: 68778024.0000 - mse: 68778024.0000 - val_loss: 63053120.0000 - val_mse: 63053120.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 7s - loss: 68398400.0000 - mse: 68398400.0000 - val_loss: 61023148.0000 - val_mse: 61023148.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 7s - loss: 68625752.0000 - mse: 68625752.0000 - val_loss: 61864324.0000 - val_mse: 61864324.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 7s - loss: 68662080.0000 - mse: 68662080.0000 - val_loss: 60161300.0000 - val_mse: 60161300.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 7s - loss: 68766496.0000 - mse: 68766496.0000 - val_loss: 60708236.0000 - val_mse: 60708236.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 7s - loss: 68438152.0000 - mse: 68438152.0000 - val_loss: 62747796.0000 - val_mse: 62747796.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 7s - loss: 68402544.0000 - mse: 68402544.0000 - val_loss: 63730632.0000 - val_mse: 63730632.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 7s - loss: 68204256.0000 - mse: 68204256.0000 - val_loss: 59790700.0000 - val_mse: 59790700.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 7s - loss: 68217264.0000 - mse: 68217264.0000 - val_loss: 60273320.0000 - val_mse: 60273320.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 7s - loss: 68302792.0000 - mse: 68302792.0000 - val_loss: 61603092.0000 - val_mse: 61603092.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 6s - loss: 68166288.0000 - mse: 68166288.0000 - val_loss: 60741368.0000 - val_mse: 60741368.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 7s - loss: 68168184.0000 - mse: 68168184.0000 - val_loss: 62844448.0000 - val_mse: 62844448.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 7s - loss: 67944600.0000 - mse: 67944600.0000 - val_loss: 62124576.0000 - val_mse: 62124576.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 7s - loss: 68410544.0000 - mse: 68410544.0000 - val_loss: 60710924.0000 - val_mse: 60710924.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 7s - loss: 68387416.0000 - mse: 68387416.0000 - val_loss: 59977116.0000 - val_mse: 59977116.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 7s - loss: 67879328.0000 - mse: 67879328.0000 - val_loss: 63988224.0000 - val_mse: 63988224.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 7s - loss: 68301784.0000 - mse: 68301784.0000 - val_loss: 62538536.0000 - val_mse: 62538536.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 7s - loss: 68000408.0000 - mse: 68000408.0000 - val_loss: 61524912.0000 - val_mse: 61524912.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 7s - loss: 68188048.0000 - mse: 68188048.0000 - val_loss: 61543592.0000 - val_mse: 61543592.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 6s - loss: 67766888.0000 - mse: 67766888.0000 - val_loss: 60512740.0000 - val_mse: 60512740.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 7s - loss: 68170352.0000 - mse: 68170352.0000 - val_loss: 60611488.0000 - val_mse: 60611488.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 7s - loss: 67689560.0000 - mse: 67689560.0000 - val_loss: 60633040.0000 - val_mse: 60633040.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 7s - loss: 68025560.0000 - mse: 68025560.0000 - val_loss: 60745780.0000 - val_mse: 60745780.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 7s - loss: 67896056.0000 - mse: 67896056.0000 - val_loss: 61391488.0000 - val_mse: 61391488.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 7s - loss: 68141568.0000 - mse: 68141568.0000 - val_loss: 60671440.0000 - val_mse: 60671440.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 7s - loss: 68187208.0000 - mse: 68187208.0000 - val_loss: 60027300.0000 - val_mse: 60027300.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 8s - loss: 68582472.0000 - mse: 68582472.0000 - val_loss: 62668084.0000 - val_mse: 62668084.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 8s - loss: 68101264.0000 - mse: 68101264.0000 - val_loss: 61639096.0000 - val_mse: 61639096.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 8s - loss: 68183272.0000 - mse: 68183272.0000 - val_loss: 60770616.0000 - val_mse: 60770616.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 8s - loss: 68027248.0000 - mse: 68027248.0000 - val_loss: 59631356.0000 - val_mse: 59631356.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 8s - loss: 68241264.0000 - mse: 68241264.0000 - val_loss: 59663940.0000 - val_mse: 59663940.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 8s - loss: 68192096.0000 - mse: 68192096.0000 - val_loss: 65841392.0000 - val_mse: 65841392.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 8s - loss: 68274224.0000 - mse: 68274224.0000 - val_loss: 61286940.0000 - val_mse: 61286940.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 7s - loss: 68303544.0000 - mse: 68303544.0000 - val_loss: 65109548.0000 - val_mse: 65109548.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 8s - loss: 68071000.0000 - mse: 68071000.0000 - val_loss: 60510300.0000 - val_mse: 60510300.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 8s - loss: 67812504.0000 - mse: 67812504.0000 - val_loss: 60078116.0000 - val_mse: 60078116.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 8s - loss: 68193224.0000 - mse: 68193224.0000 - val_loss: 60485124.0000 - val_mse: 60485124.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 8s - loss: 68130784.0000 - mse: 68130784.0000 - val_loss: 61144220.0000 - val_mse: 61144220.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 8s - loss: 68004512.0000 - mse: 68004512.0000 - val_loss: 62903496.0000 - val_mse: 62903496.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 8s - loss: 68258792.0000 - mse: 68258792.0000 - val_loss: 58592220.0000 - val_mse: 58592220.0000\n",
      "Epoch 63/1000\n",
      "6516/6516 - 8s - loss: 68177576.0000 - mse: 68177576.0000 - val_loss: 61670620.0000 - val_mse: 61670620.0000\n",
      "Epoch 64/1000\n",
      "6516/6516 - 8s - loss: 68092936.0000 - mse: 68092936.0000 - val_loss: 63683084.0000 - val_mse: 63683084.0000\n",
      "Epoch 65/1000\n",
      "6516/6516 - 8s - loss: 68067016.0000 - mse: 68067016.0000 - val_loss: 60362396.0000 - val_mse: 60362396.0000\n",
      "Epoch 66/1000\n",
      "6516/6516 - 6s - loss: 67971112.0000 - mse: 67971112.0000 - val_loss: 60062368.0000 - val_mse: 60062368.0000\n",
      "Epoch 67/1000\n",
      "6516/6516 - 6s - loss: 68374576.0000 - mse: 68374576.0000 - val_loss: 61982640.0000 - val_mse: 61982640.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "6516/6516 - 7s - loss: 68570600.0000 - mse: 68570600.0000 - val_loss: 63113164.0000 - val_mse: 63113164.0000\n",
      "Epoch 69/1000\n",
      "6516/6516 - 7s - loss: 68245096.0000 - mse: 68245096.0000 - val_loss: 59615420.0000 - val_mse: 59615420.0000\n",
      "Epoch 70/1000\n",
      "6516/6516 - 7s - loss: 68288480.0000 - mse: 68288480.0000 - val_loss: 61830664.0000 - val_mse: 61830664.0000\n",
      "Epoch 71/1000\n",
      "6516/6516 - 8s - loss: 68126472.0000 - mse: 68126472.0000 - val_loss: 60681668.0000 - val_mse: 60681668.0000\n",
      "Epoch 72/1000\n",
      "6516/6516 - 8s - loss: 68081064.0000 - mse: 68081064.0000 - val_loss: 61259112.0000 - val_mse: 61259112.0000\n",
      "Epoch 73/1000\n",
      "6516/6516 - 8s - loss: 68324848.0000 - mse: 68324848.0000 - val_loss: 60128884.0000 - val_mse: 60128884.0000\n",
      "Epoch 74/1000\n",
      "6516/6516 - 7s - loss: 68421280.0000 - mse: 68421280.0000 - val_loss: 61176876.0000 - val_mse: 61176876.0000\n",
      "Epoch 75/1000\n",
      "6516/6516 - 7s - loss: 68119888.0000 - mse: 68119888.0000 - val_loss: 61682056.0000 - val_mse: 61682056.0000\n",
      "Epoch 76/1000\n",
      "6516/6516 - 7s - loss: 68277784.0000 - mse: 68277784.0000 - val_loss: 59886452.0000 - val_mse: 59886452.0000\n",
      "Epoch 77/1000\n",
      "6516/6516 - 6s - loss: 68264408.0000 - mse: 68264408.0000 - val_loss: 59588496.0000 - val_mse: 59588496.0000\n",
      "Epoch 78/1000\n",
      "6516/6516 - 7s - loss: 68224192.0000 - mse: 68224192.0000 - val_loss: 60479236.0000 - val_mse: 60479236.0000\n",
      "Epoch 79/1000\n",
      "6516/6516 - 7s - loss: 68181816.0000 - mse: 68181816.0000 - val_loss: 62168320.0000 - val_mse: 62168320.0000\n",
      "Epoch 80/1000\n",
      "6516/6516 - 7s - loss: 68087896.0000 - mse: 68087896.0000 - val_loss: 61494856.0000 - val_mse: 61494856.0000\n",
      "Epoch 81/1000\n",
      "6516/6516 - 7s - loss: 68166912.0000 - mse: 68166912.0000 - val_loss: 61216480.0000 - val_mse: 61216480.0000\n",
      "Epoch 82/1000\n",
      "6516/6516 - 8s - loss: 68320912.0000 - mse: 68320912.0000 - val_loss: 59779448.0000 - val_mse: 59779448.0000\n",
      "Epoch 83/1000\n",
      "6516/6516 - 8s - loss: 68365344.0000 - mse: 68365344.0000 - val_loss: 60864500.0000 - val_mse: 60864500.0000\n",
      "Epoch 84/1000\n",
      "6516/6516 - 7s - loss: 68199400.0000 - mse: 68199400.0000 - val_loss: 61011472.0000 - val_mse: 61011472.0000\n",
      "Epoch 85/1000\n",
      "6516/6516 - 7s - loss: 68396464.0000 - mse: 68396464.0000 - val_loss: 62182128.0000 - val_mse: 62182128.0000\n",
      "Epoch 86/1000\n",
      "6516/6516 - 7s - loss: 68279288.0000 - mse: 68279288.0000 - val_loss: 58457112.0000 - val_mse: 58457112.0000\n",
      "Epoch 87/1000\n",
      "6516/6516 - 8s - loss: 68018488.0000 - mse: 68018488.0000 - val_loss: 60458124.0000 - val_mse: 60458124.0000\n",
      "Epoch 88/1000\n",
      "6516/6516 - 7s - loss: 68534680.0000 - mse: 68534680.0000 - val_loss: 59892044.0000 - val_mse: 59892044.0000\n",
      "Epoch 89/1000\n",
      "6516/6516 - 7s - loss: 68083328.0000 - mse: 68083328.0000 - val_loss: 59525844.0000 - val_mse: 59525844.0000\n",
      "Epoch 90/1000\n",
      "6516/6516 - 8s - loss: 68047560.0000 - mse: 68047560.0000 - val_loss: 61113348.0000 - val_mse: 61113348.0000\n",
      "Epoch 91/1000\n",
      "6516/6516 - 8s - loss: 68726960.0000 - mse: 68726960.0000 - val_loss: 61157092.0000 - val_mse: 61157092.0000\n",
      "Epoch 92/1000\n",
      "6516/6516 - 8s - loss: 68224768.0000 - mse: 68224768.0000 - val_loss: 61733580.0000 - val_mse: 61733580.0000\n",
      "Epoch 93/1000\n",
      "6516/6516 - 8s - loss: 69321536.0000 - mse: 69321536.0000 - val_loss: 59916944.0000 - val_mse: 59916944.0000\n",
      "Epoch 94/1000\n",
      "6516/6516 - 8s - loss: 69077680.0000 - mse: 69077680.0000 - val_loss: 58370848.0000 - val_mse: 58370848.0000\n",
      "Epoch 95/1000\n",
      "6516/6516 - 8s - loss: 68893672.0000 - mse: 68893672.0000 - val_loss: 60959704.0000 - val_mse: 60959704.0000\n",
      "Epoch 96/1000\n",
      "6516/6516 - 7s - loss: 68509856.0000 - mse: 68509856.0000 - val_loss: 61387056.0000 - val_mse: 61387056.0000\n",
      "Epoch 97/1000\n",
      "6516/6516 - 8s - loss: 68792576.0000 - mse: 68792576.0000 - val_loss: 63558856.0000 - val_mse: 63558856.0000\n",
      "Epoch 98/1000\n",
      "6516/6516 - 8s - loss: 69707296.0000 - mse: 69707296.0000 - val_loss: 61292252.0000 - val_mse: 61292252.0000\n",
      "Epoch 99/1000\n",
      "6516/6516 - 7s - loss: 69148328.0000 - mse: 69148328.0000 - val_loss: 60708404.0000 - val_mse: 60708404.0000\n",
      "Epoch 100/1000\n",
      "6516/6516 - 7s - loss: 69529544.0000 - mse: 69529544.0000 - val_loss: 60304944.0000 - val_mse: 60304944.0000\n",
      "Epoch 101/1000\n",
      "6516/6516 - 6s - loss: 69464384.0000 - mse: 69464384.0000 - val_loss: 62012812.0000 - val_mse: 62012812.0000\n",
      "Epoch 102/1000\n",
      "6516/6516 - 7s - loss: 69244088.0000 - mse: 69244088.0000 - val_loss: 62234788.0000 - val_mse: 62234788.0000\n",
      "Epoch 103/1000\n",
      "6516/6516 - 7s - loss: 69352240.0000 - mse: 69352240.0000 - val_loss: 58939792.0000 - val_mse: 58939792.0000\n",
      "Epoch 104/1000\n",
      "6516/6516 - 7s - loss: 68992840.0000 - mse: 68992840.0000 - val_loss: 60408364.0000 - val_mse: 60408364.0000\n",
      "Epoch 105/1000\n",
      "6516/6516 - 7s - loss: 69432312.0000 - mse: 69432312.0000 - val_loss: 58622140.0000 - val_mse: 58622140.0000\n",
      "Epoch 106/1000\n",
      "6516/6516 - 7s - loss: 68760872.0000 - mse: 68760872.0000 - val_loss: 58804072.0000 - val_mse: 58804072.0000\n",
      "Epoch 107/1000\n",
      "6516/6516 - 7s - loss: 69108928.0000 - mse: 69108928.0000 - val_loss: 59433564.0000 - val_mse: 59433564.0000\n",
      "Epoch 108/1000\n",
      "6516/6516 - 6s - loss: 69532512.0000 - mse: 69532512.0000 - val_loss: 57163704.0000 - val_mse: 57163704.0000\n",
      "Epoch 109/1000\n",
      "6516/6516 - 6s - loss: 68659752.0000 - mse: 68659752.0000 - val_loss: 62204132.0000 - val_mse: 62204132.0000\n",
      "Epoch 110/1000\n",
      "6516/6516 - 7s - loss: 68920088.0000 - mse: 68920088.0000 - val_loss: 58933360.0000 - val_mse: 58933360.0000\n",
      "Epoch 111/1000\n",
      "6516/6516 - 7s - loss: 68528640.0000 - mse: 68528640.0000 - val_loss: 59323848.0000 - val_mse: 59323848.0000\n",
      "Epoch 112/1000\n",
      "6516/6516 - 7s - loss: 68587424.0000 - mse: 68587424.0000 - val_loss: 58850112.0000 - val_mse: 58850112.0000\n",
      "Epoch 113/1000\n",
      "6516/6516 - 6s - loss: 68568224.0000 - mse: 68568224.0000 - val_loss: 58765652.0000 - val_mse: 58765652.0000\n",
      "Epoch 114/1000\n",
      "6516/6516 - 6s - loss: 68428632.0000 - mse: 68428632.0000 - val_loss: 61983508.0000 - val_mse: 61983508.0000\n",
      "Epoch 115/1000\n",
      "6516/6516 - 6s - loss: 68510296.0000 - mse: 68510296.0000 - val_loss: 57714204.0000 - val_mse: 57714204.0000\n",
      "Epoch 116/1000\n",
      "6516/6516 - 6s - loss: 68229760.0000 - mse: 68229760.0000 - val_loss: 59217300.0000 - val_mse: 59217300.0000\n",
      "Epoch 117/1000\n",
      "6516/6516 - 6s - loss: 67917600.0000 - mse: 67917600.0000 - val_loss: 61442296.0000 - val_mse: 61442296.0000\n",
      "Epoch 118/1000\n",
      "6516/6516 - 6s - loss: 68713968.0000 - mse: 68713968.0000 - val_loss: 57269712.0000 - val_mse: 57269712.0000\n",
      "Epoch 119/1000\n",
      "6516/6516 - 6s - loss: 68323120.0000 - mse: 68323120.0000 - val_loss: 59953780.0000 - val_mse: 59953780.0000\n",
      "Epoch 120/1000\n",
      "6516/6516 - 6s - loss: 68368840.0000 - mse: 68368840.0000 - val_loss: 61669264.0000 - val_mse: 61669264.0000\n",
      "Epoch 121/1000\n",
      "6516/6516 - 7s - loss: 68656472.0000 - mse: 68656472.0000 - val_loss: 58709416.0000 - val_mse: 58709416.0000\n",
      "Epoch 122/1000\n",
      "6516/6516 - 7s - loss: 68920832.0000 - mse: 68920832.0000 - val_loss: 58671084.0000 - val_mse: 58671084.0000\n",
      "Epoch 123/1000\n",
      "6516/6516 - 7s - loss: 68194640.0000 - mse: 68194640.0000 - val_loss: 59976048.0000 - val_mse: 59976048.0000\n",
      "Epoch 124/1000\n",
      "6516/6516 - 6s - loss: 68003072.0000 - mse: 68003072.0000 - val_loss: 59207396.0000 - val_mse: 59207396.0000\n",
      "Epoch 125/1000\n",
      "6516/6516 - 7s - loss: 68095008.0000 - mse: 68095008.0000 - val_loss: 60436392.0000 - val_mse: 60436392.0000\n",
      "Epoch 126/1000\n",
      "6516/6516 - 7s - loss: 68011176.0000 - mse: 68011176.0000 - val_loss: 59463284.0000 - val_mse: 59463284.0000\n",
      "Epoch 127/1000\n",
      "6516/6516 - 7s - loss: 68080904.0000 - mse: 68080904.0000 - val_loss: 60714548.0000 - val_mse: 60714548.0000\n",
      "Epoch 128/1000\n",
      "6516/6516 - 6s - loss: 68209320.0000 - mse: 68209320.0000 - val_loss: 58662296.0000 - val_mse: 58662296.0000\n",
      "Epoch 129/1000\n",
      "6516/6516 - 7s - loss: 68194232.0000 - mse: 68194232.0000 - val_loss: 61089180.0000 - val_mse: 61089180.0000\n",
      "Epoch 130/1000\n",
      "6516/6516 - 6s - loss: 68085288.0000 - mse: 68085288.0000 - val_loss: 58028544.0000 - val_mse: 58028544.0000\n",
      "Epoch 131/1000\n",
      "6516/6516 - 6s - loss: 67852984.0000 - mse: 67852984.0000 - val_loss: 58315524.0000 - val_mse: 58315524.0000\n",
      "Epoch 132/1000\n",
      "6516/6516 - 6s - loss: 67902904.0000 - mse: 67902904.0000 - val_loss: 59532624.0000 - val_mse: 59532624.0000\n",
      "Epoch 133/1000\n",
      "6516/6516 - 6s - loss: 68120560.0000 - mse: 68120560.0000 - val_loss: 58611496.0000 - val_mse: 58611496.0000\n",
      "Epoch 134/1000\n",
      "6516/6516 - 6s - loss: 68696744.0000 - mse: 68696744.0000 - val_loss: 58291528.0000 - val_mse: 58291528.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000\n",
      "6516/6516 - 7s - loss: 67840208.0000 - mse: 67840208.0000 - val_loss: 57602988.0000 - val_mse: 57602988.0000\n",
      "Epoch 136/1000\n",
      "6516/6516 - 6s - loss: 68106712.0000 - mse: 68106712.0000 - val_loss: 58563276.0000 - val_mse: 58563276.0000\n",
      "Epoch 137/1000\n",
      "6516/6516 - 8s - loss: 67580328.0000 - mse: 67580328.0000 - val_loss: 59077736.0000 - val_mse: 59077736.0000\n",
      "Epoch 138/1000\n",
      "6516/6516 - 9s - loss: 67780104.0000 - mse: 67780104.0000 - val_loss: 59776728.0000 - val_mse: 59776728.0000\n"
     ]
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28805829265604854"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 9s - loss: 80973264.0000 - mse: 80973264.0000 - val_loss: 65512376.0000 - val_mse: 65512376.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 7s - loss: 73739720.0000 - mse: 73739720.0000 - val_loss: 64294292.0000 - val_mse: 64294292.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 7s - loss: 71549536.0000 - mse: 71549536.0000 - val_loss: 62250440.0000 - val_mse: 62250440.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 8s - loss: 70638360.0000 - mse: 70638360.0000 - val_loss: 61502764.0000 - val_mse: 61502764.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 10s - loss: 70281160.0000 - mse: 70281160.0000 - val_loss: 61545588.0000 - val_mse: 61545588.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 10s - loss: 70506344.0000 - mse: 70506344.0000 - val_loss: 61009572.0000 - val_mse: 61009572.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 7s - loss: 69355112.0000 - mse: 69355112.0000 - val_loss: 60848416.0000 - val_mse: 60848416.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 8s - loss: 69344128.0000 - mse: 69344128.0000 - val_loss: 59710572.0000 - val_mse: 59710572.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 9s - loss: 69305400.0000 - mse: 69305400.0000 - val_loss: 59301780.0000 - val_mse: 59301780.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 9s - loss: 68552656.0000 - mse: 68552656.0000 - val_loss: 60096244.0000 - val_mse: 60096244.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 10s - loss: 68556744.0000 - mse: 68556744.0000 - val_loss: 61644156.0000 - val_mse: 61644156.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 7s - loss: 68472008.0000 - mse: 68472008.0000 - val_loss: 58516312.0000 - val_mse: 58516312.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 8s - loss: 68377496.0000 - mse: 68377496.0000 - val_loss: 60077896.0000 - val_mse: 60077896.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 11s - loss: 68752120.0000 - mse: 68752120.0000 - val_loss: 59347988.0000 - val_mse: 59347988.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 8s - loss: 68238056.0000 - mse: 68238056.0000 - val_loss: 59247712.0000 - val_mse: 59247712.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 7s - loss: 68498624.0000 - mse: 68498624.0000 - val_loss: 59931520.0000 - val_mse: 59931520.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 7s - loss: 68400784.0000 - mse: 68400784.0000 - val_loss: 61905440.0000 - val_mse: 61905440.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 7s - loss: 68620184.0000 - mse: 68620184.0000 - val_loss: 59952528.0000 - val_mse: 59952528.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 8s - loss: 68106912.0000 - mse: 68106912.0000 - val_loss: 58614196.0000 - val_mse: 58614196.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 7s - loss: 67711160.0000 - mse: 67711160.0000 - val_loss: 61164172.0000 - val_mse: 61164172.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 7s - loss: 68005040.0000 - mse: 68005040.0000 - val_loss: 59882104.0000 - val_mse: 59882104.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 7s - loss: 67496264.0000 - mse: 67496264.0000 - val_loss: 60384212.0000 - val_mse: 60384212.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 8s - loss: 68003824.0000 - mse: 68003824.0000 - val_loss: 59994380.0000 - val_mse: 59994380.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 7s - loss: 68194136.0000 - mse: 68194136.0000 - val_loss: 59324272.0000 - val_mse: 59324272.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 8s - loss: 68191608.0000 - mse: 68191608.0000 - val_loss: 60867756.0000 - val_mse: 60867756.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 7s - loss: 68404320.0000 - mse: 68404320.0000 - val_loss: 63483892.0000 - val_mse: 63483892.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 7s - loss: 68077376.0000 - mse: 68077376.0000 - val_loss: 60107620.0000 - val_mse: 60107620.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 7s - loss: 68021928.0000 - mse: 68021928.0000 - val_loss: 60525300.0000 - val_mse: 60525300.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 7s - loss: 68144960.0000 - mse: 68144960.0000 - val_loss: 62856496.0000 - val_mse: 62856496.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 7s - loss: 68315504.0000 - mse: 68315504.0000 - val_loss: 65342272.0000 - val_mse: 65342272.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 8s - loss: 68102144.0000 - mse: 68102144.0000 - val_loss: 59996740.0000 - val_mse: 59996740.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 8s - loss: 68246872.0000 - mse: 68246872.0000 - val_loss: 60161752.0000 - val_mse: 60161752.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 8s - loss: 68173104.0000 - mse: 68173104.0000 - val_loss: 60294220.0000 - val_mse: 60294220.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 8s - loss: 67941768.0000 - mse: 67941768.0000 - val_loss: 60980360.0000 - val_mse: 60980360.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 8s - loss: 68288512.0000 - mse: 68288512.0000 - val_loss: 60601840.0000 - val_mse: 60601840.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 7s - loss: 68225808.0000 - mse: 68225808.0000 - val_loss: 60631660.0000 - val_mse: 60631660.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 7s - loss: 68189240.0000 - mse: 68189240.0000 - val_loss: 58984608.0000 - val_mse: 58984608.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 7s - loss: 68345888.0000 - mse: 68345888.0000 - val_loss: 62332132.0000 - val_mse: 62332132.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 8s - loss: 68251120.0000 - mse: 68251120.0000 - val_loss: 63399104.0000 - val_mse: 63399104.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 7s - loss: 67970504.0000 - mse: 67970504.0000 - val_loss: 62074460.0000 - val_mse: 62074460.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 7s - loss: 68313120.0000 - mse: 68313120.0000 - val_loss: 59781316.0000 - val_mse: 59781316.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 7s - loss: 68238488.0000 - mse: 68238488.0000 - val_loss: 63648188.0000 - val_mse: 63648188.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(38, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(38, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(38, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(38, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(38, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2750474742138307"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set \n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 9s - loss: 84448568.0000 - mse: 84448568.0000 - val_loss: 67753872.0000 - val_mse: 67753872.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 10s - loss: 77042480.0000 - mse: 77042480.0000 - val_loss: 65429460.0000 - val_mse: 65429460.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 8s - loss: 75183416.0000 - mse: 75183416.0000 - val_loss: 62603152.0000 - val_mse: 62603152.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 8s - loss: 73660296.0000 - mse: 73660296.0000 - val_loss: 61173508.0000 - val_mse: 61173508.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 7s - loss: 72484088.0000 - mse: 72484088.0000 - val_loss: 61846776.0000 - val_mse: 61846776.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 9s - loss: 72130792.0000 - mse: 72130792.0000 - val_loss: 62508960.0000 - val_mse: 62508960.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 9s - loss: 71725680.0000 - mse: 71725680.0000 - val_loss: 63126096.0000 - val_mse: 63126096.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 9s - loss: 70955224.0000 - mse: 70955224.0000 - val_loss: 60288364.0000 - val_mse: 60288364.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 9s - loss: 71051384.0000 - mse: 71051384.0000 - val_loss: 61879412.0000 - val_mse: 61879412.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 10s - loss: 70679560.0000 - mse: 70679560.0000 - val_loss: 60483588.0000 - val_mse: 60483588.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 8s - loss: 70489712.0000 - mse: 70489712.0000 - val_loss: 62039756.0000 - val_mse: 62039756.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 14s - loss: 70648872.0000 - mse: 70648872.0000 - val_loss: 61807840.0000 - val_mse: 61807840.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 10s - loss: 69914032.0000 - mse: 69914032.0000 - val_loss: 61377980.0000 - val_mse: 61377980.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 9s - loss: 70223488.0000 - mse: 70223488.0000 - val_loss: 61252420.0000 - val_mse: 61252420.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 8s - loss: 70348184.0000 - mse: 70348184.0000 - val_loss: 61051300.0000 - val_mse: 61051300.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 9s - loss: 69667424.0000 - mse: 69667424.0000 - val_loss: 58541572.0000 - val_mse: 58541572.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 8s - loss: 69858040.0000 - mse: 69858040.0000 - val_loss: 59280444.0000 - val_mse: 59280444.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 7s - loss: 69461640.0000 - mse: 69461640.0000 - val_loss: 63046164.0000 - val_mse: 63046164.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 8s - loss: 69734048.0000 - mse: 69734048.0000 - val_loss: 59955772.0000 - val_mse: 59955772.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 7s - loss: 69649392.0000 - mse: 69649392.0000 - val_loss: 58301356.0000 - val_mse: 58301356.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 8s - loss: 69576776.0000 - mse: 69576776.0000 - val_loss: 61240896.0000 - val_mse: 61240896.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 9s - loss: 69470344.0000 - mse: 69470344.0000 - val_loss: 58128836.0000 - val_mse: 58128836.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 9s - loss: 69218256.0000 - mse: 69218256.0000 - val_loss: 61772260.0000 - val_mse: 61772260.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 8s - loss: 69049968.0000 - mse: 69049968.0000 - val_loss: 58802840.0000 - val_mse: 58802840.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 8s - loss: 69046128.0000 - mse: 69046128.0000 - val_loss: 58130536.0000 - val_mse: 58130536.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 9s - loss: 68893512.0000 - mse: 68893512.0000 - val_loss: 60209184.0000 - val_mse: 60209184.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 9s - loss: 69375240.0000 - mse: 69375240.0000 - val_loss: 57929316.0000 - val_mse: 57929316.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 10s - loss: 69197344.0000 - mse: 69197344.0000 - val_loss: 60390996.0000 - val_mse: 60390996.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 8s - loss: 69042688.0000 - mse: 69042688.0000 - val_loss: 57894832.0000 - val_mse: 57894832.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 7s - loss: 69201944.0000 - mse: 69201944.0000 - val_loss: 60109552.0000 - val_mse: 60109552.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 9s - loss: 69042184.0000 - mse: 69042184.0000 - val_loss: 59807840.0000 - val_mse: 59807840.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 9s - loss: 69435760.0000 - mse: 69435760.0000 - val_loss: 61587672.0000 - val_mse: 61587672.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 8s - loss: 69902072.0000 - mse: 69902072.0000 - val_loss: 59842212.0000 - val_mse: 59842212.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 9s - loss: 69572608.0000 - mse: 69572608.0000 - val_loss: 58557560.0000 - val_mse: 58557560.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 7s - loss: 68840216.0000 - mse: 68840216.0000 - val_loss: 59296872.0000 - val_mse: 59296872.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 9s - loss: 68898192.0000 - mse: 68898192.0000 - val_loss: 58200424.0000 - val_mse: 58200424.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 10s - loss: 69346056.0000 - mse: 69346056.0000 - val_loss: 63993412.0000 - val_mse: 63993412.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 9s - loss: 68611144.0000 - mse: 68611144.0000 - val_loss: 60890652.0000 - val_mse: 60890652.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 9s - loss: 69731800.0000 - mse: 69731800.0000 - val_loss: 57578196.0000 - val_mse: 57578196.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 9s - loss: 68747648.0000 - mse: 68747648.0000 - val_loss: 58667080.0000 - val_mse: 58667080.0000\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-89d0058c256c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(76, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(38, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(19, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 8s - loss: 83926712.0000 - mse: 83926712.0000 - val_loss: 65887468.0000 - val_mse: 65887468.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 8s - loss: 75801272.0000 - mse: 75801272.0000 - val_loss: 64189432.0000 - val_mse: 64189432.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 8s - loss: 74323688.0000 - mse: 74323688.0000 - val_loss: 62852948.0000 - val_mse: 62852948.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 8s - loss: 72815624.0000 - mse: 72815624.0000 - val_loss: 63091416.0000 - val_mse: 63091416.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 8s - loss: 71639024.0000 - mse: 71639024.0000 - val_loss: 60272212.0000 - val_mse: 60272212.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 10s - loss: 70888640.0000 - mse: 70888640.0000 - val_loss: 61631728.0000 - val_mse: 61631728.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 11s - loss: 70995312.0000 - mse: 70995312.0000 - val_loss: 59987276.0000 - val_mse: 59987276.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 9s - loss: 70011272.0000 - mse: 70011272.0000 - val_loss: 59003368.0000 - val_mse: 59003368.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 8s - loss: 69630664.0000 - mse: 69630664.0000 - val_loss: 58877392.0000 - val_mse: 58877392.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 8s - loss: 69974656.0000 - mse: 69974656.0000 - val_loss: 58724296.0000 - val_mse: 58724296.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 8s - loss: 69776176.0000 - mse: 69776176.0000 - val_loss: 59907684.0000 - val_mse: 59907684.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 8s - loss: 68942936.0000 - mse: 68942936.0000 - val_loss: 58798004.0000 - val_mse: 58798004.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 8s - loss: 68568360.0000 - mse: 68568360.0000 - val_loss: 60397988.0000 - val_mse: 60397988.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 8s - loss: 68768800.0000 - mse: 68768800.0000 - val_loss: 58377476.0000 - val_mse: 58377476.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 8s - loss: 68850400.0000 - mse: 68850400.0000 - val_loss: 59122968.0000 - val_mse: 59122968.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 8s - loss: 68607208.0000 - mse: 68607208.0000 - val_loss: 59382732.0000 - val_mse: 59382732.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 8s - loss: 68619376.0000 - mse: 68619376.0000 - val_loss: 57848440.0000 - val_mse: 57848440.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 8s - loss: 68441520.0000 - mse: 68441520.0000 - val_loss: 57569780.0000 - val_mse: 57569780.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 8s - loss: 68433808.0000 - mse: 68433808.0000 - val_loss: 58172104.0000 - val_mse: 58172104.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 8s - loss: 68358504.0000 - mse: 68358504.0000 - val_loss: 59398128.0000 - val_mse: 59398128.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 8s - loss: 68050544.0000 - mse: 68050544.0000 - val_loss: 58670228.0000 - val_mse: 58670228.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 8s - loss: 68160432.0000 - mse: 68160432.0000 - val_loss: 57636784.0000 - val_mse: 57636784.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 8s - loss: 68144408.0000 - mse: 68144408.0000 - val_loss: 58407476.0000 - val_mse: 58407476.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 8s - loss: 68007632.0000 - mse: 68007632.0000 - val_loss: 58490532.0000 - val_mse: 58490532.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 8s - loss: 68168448.0000 - mse: 68168448.0000 - val_loss: 59411392.0000 - val_mse: 59411392.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 8s - loss: 68116120.0000 - mse: 68116120.0000 - val_loss: 59687852.0000 - val_mse: 59687852.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 8s - loss: 68263168.0000 - mse: 68263168.0000 - val_loss: 57550852.0000 - val_mse: 57550852.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 8s - loss: 68400480.0000 - mse: 68400480.0000 - val_loss: 59118944.0000 - val_mse: 59118944.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 8s - loss: 68072760.0000 - mse: 68072760.0000 - val_loss: 58236320.0000 - val_mse: 58236320.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 8s - loss: 68047072.0000 - mse: 68047072.0000 - val_loss: 56146712.0000 - val_mse: 56146712.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 8s - loss: 68277760.0000 - mse: 68277760.0000 - val_loss: 60526748.0000 - val_mse: 60526748.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 8s - loss: 68134744.0000 - mse: 68134744.0000 - val_loss: 60152064.0000 - val_mse: 60152064.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 8s - loss: 68226640.0000 - mse: 68226640.0000 - val_loss: 57358652.0000 - val_mse: 57358652.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 8s - loss: 67805336.0000 - mse: 67805336.0000 - val_loss: 60160160.0000 - val_mse: 60160160.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 8s - loss: 68372744.0000 - mse: 68372744.0000 - val_loss: 59748332.0000 - val_mse: 59748332.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 8s - loss: 67920960.0000 - mse: 67920960.0000 - val_loss: 60737892.0000 - val_mse: 60737892.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 8s - loss: 68197568.0000 - mse: 68197568.0000 - val_loss: 58871464.0000 - val_mse: 58871464.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 8s - loss: 68170792.0000 - mse: 68170792.0000 - val_loss: 58536560.0000 - val_mse: 58536560.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 8s - loss: 68203232.0000 - mse: 68203232.0000 - val_loss: 61297516.0000 - val_mse: 61297516.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 8s - loss: 68067552.0000 - mse: 68067552.0000 - val_loss: 59426168.0000 - val_mse: 59426168.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 8s - loss: 68462144.0000 - mse: 68462144.0000 - val_loss: 60056592.0000 - val_mse: 60056592.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 8s - loss: 67768784.0000 - mse: 67768784.0000 - val_loss: 57029624.0000 - val_mse: 57029624.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 8s - loss: 67831432.0000 - mse: 67831432.0000 - val_loss: 58622948.0000 - val_mse: 58622948.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 8s - loss: 68361152.0000 - mse: 68361152.0000 - val_loss: 58335148.0000 - val_mse: 58335148.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 8s - loss: 68112736.0000 - mse: 68112736.0000 - val_loss: 60287772.0000 - val_mse: 60287772.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 8s - loss: 68411920.0000 - mse: 68411920.0000 - val_loss: 56476492.0000 - val_mse: 56476492.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 8s - loss: 67491088.0000 - mse: 67491088.0000 - val_loss: 58048752.0000 - val_mse: 58048752.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 8s - loss: 67401616.0000 - mse: 67401616.0000 - val_loss: 57976156.0000 - val_mse: 57976156.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 8s - loss: 67605784.0000 - mse: 67605784.0000 - val_loss: 64539524.0000 - val_mse: 64539524.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 8s - loss: 68049984.0000 - mse: 68049984.0000 - val_loss: 57511488.0000 - val_mse: 57511488.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 8s - loss: 66793524.0000 - mse: 66793524.0000 - val_loss: 55759296.0000 - val_mse: 55759296.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 8s - loss: 67317304.0000 - mse: 67317304.0000 - val_loss: 55169248.0000 - val_mse: 55169248.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 8s - loss: 68193744.0000 - mse: 68193744.0000 - val_loss: 60271508.0000 - val_mse: 60271508.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 8s - loss: 67332032.0000 - mse: 67332032.0000 - val_loss: 56224072.0000 - val_mse: 56224072.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 8s - loss: 67926712.0000 - mse: 67926712.0000 - val_loss: 56117140.0000 - val_mse: 56117140.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 8s - loss: 67969272.0000 - mse: 67969272.0000 - val_loss: 56020052.0000 - val_mse: 56020052.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 8s - loss: 67792880.0000 - mse: 67792880.0000 - val_loss: 59705296.0000 - val_mse: 59705296.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 8s - loss: 67988736.0000 - mse: 67988736.0000 - val_loss: 55998324.0000 - val_mse: 55998324.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 8s - loss: 68180408.0000 - mse: 68180408.0000 - val_loss: 55786624.0000 - val_mse: 55786624.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 8s - loss: 68107144.0000 - mse: 68107144.0000 - val_loss: 61402380.0000 - val_mse: 61402380.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 8s - loss: 67653784.0000 - mse: 67653784.0000 - val_loss: 57227980.0000 - val_mse: 57227980.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 8s - loss: 67781400.0000 - mse: 67781400.0000 - val_loss: 55651228.0000 - val_mse: 55651228.0000\n",
      "Epoch 63/1000\n",
      "6516/6516 - 8s - loss: 67876440.0000 - mse: 67876440.0000 - val_loss: 56974228.0000 - val_mse: 56974228.0000\n",
      "Epoch 64/1000\n",
      "6516/6516 - 8s - loss: 67913512.0000 - mse: 67913512.0000 - val_loss: 56938996.0000 - val_mse: 56938996.0000\n",
      "Epoch 65/1000\n",
      "6516/6516 - 8s - loss: 68420504.0000 - mse: 68420504.0000 - val_loss: 57876364.0000 - val_mse: 57876364.0000\n",
      "Epoch 66/1000\n",
      "6516/6516 - 8s - loss: 68162832.0000 - mse: 68162832.0000 - val_loss: 58671404.0000 - val_mse: 58671404.0000\n",
      "Epoch 67/1000\n",
      "6516/6516 - 8s - loss: 67968088.0000 - mse: 67968088.0000 - val_loss: 57044660.0000 - val_mse: 57044660.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "6516/6516 - 8s - loss: 68482320.0000 - mse: 68482320.0000 - val_loss: 61251240.0000 - val_mse: 61251240.0000\n",
      "Epoch 69/1000\n",
      "6516/6516 - 8s - loss: 67910592.0000 - mse: 67910592.0000 - val_loss: 60792204.0000 - val_mse: 60792204.0000\n",
      "Epoch 70/1000\n",
      "6516/6516 - 8s - loss: 68337880.0000 - mse: 68337880.0000 - val_loss: 56186536.0000 - val_mse: 56186536.0000\n",
      "Epoch 71/1000\n",
      "6516/6516 - 10s - loss: 67997328.0000 - mse: 67997328.0000 - val_loss: 62465700.0000 - val_mse: 62465700.0000\n",
      "Epoch 72/1000\n",
      "6516/6516 - 9s - loss: 68280080.0000 - mse: 68280080.0000 - val_loss: 57984388.0000 - val_mse: 57984388.0000\n",
      "Epoch 73/1000\n",
      "6516/6516 - 8s - loss: 68401024.0000 - mse: 68401024.0000 - val_loss: 55630460.0000 - val_mse: 55630460.0000\n",
      "Epoch 74/1000\n",
      "6516/6516 - 8s - loss: 68214464.0000 - mse: 68214464.0000 - val_loss: 60327548.0000 - val_mse: 60327548.0000\n",
      "Epoch 75/1000\n",
      "6516/6516 - 8s - loss: 67841568.0000 - mse: 67841568.0000 - val_loss: 55165096.0000 - val_mse: 55165096.0000\n",
      "Epoch 76/1000\n",
      "6516/6516 - 8s - loss: 68072560.0000 - mse: 68072560.0000 - val_loss: 61860168.0000 - val_mse: 61860168.0000\n",
      "Epoch 77/1000\n",
      "6516/6516 - 8s - loss: 68306264.0000 - mse: 68306264.0000 - val_loss: 56007316.0000 - val_mse: 56007316.0000\n",
      "Epoch 78/1000\n",
      "6516/6516 - 8s - loss: 68388216.0000 - mse: 68388216.0000 - val_loss: 59704784.0000 - val_mse: 59704784.0000\n",
      "Epoch 79/1000\n",
      "6516/6516 - 8s - loss: 68604976.0000 - mse: 68604976.0000 - val_loss: 64125464.0000 - val_mse: 64125464.0000\n",
      "Epoch 80/1000\n",
      "6516/6516 - 8s - loss: 68381552.0000 - mse: 68381552.0000 - val_loss: 55618436.0000 - val_mse: 55618436.0000\n",
      "Epoch 81/1000\n",
      "6516/6516 - 8s - loss: 68787232.0000 - mse: 68787232.0000 - val_loss: 58694244.0000 - val_mse: 58694244.0000\n",
      "Epoch 82/1000\n",
      "6516/6516 - 8s - loss: 67876248.0000 - mse: 67876248.0000 - val_loss: 56958528.0000 - val_mse: 56958528.0000\n",
      "Epoch 83/1000\n",
      "6516/6516 - 8s - loss: 69140696.0000 - mse: 69140696.0000 - val_loss: 57011624.0000 - val_mse: 57011624.0000\n",
      "Epoch 84/1000\n",
      "6516/6516 - 8s - loss: 68556576.0000 - mse: 68556576.0000 - val_loss: 55488616.0000 - val_mse: 55488616.0000\n",
      "Epoch 85/1000\n",
      "6516/6516 - 8s - loss: 68271168.0000 - mse: 68271168.0000 - val_loss: 58503984.0000 - val_mse: 58503984.0000\n",
      "Epoch 86/1000\n",
      "6516/6516 - 8s - loss: 68670280.0000 - mse: 68670280.0000 - val_loss: 62107396.0000 - val_mse: 62107396.0000\n",
      "Epoch 87/1000\n",
      "6516/6516 - 8s - loss: 68537104.0000 - mse: 68537104.0000 - val_loss: 62756056.0000 - val_mse: 62756056.0000\n",
      "Epoch 88/1000\n",
      "6516/6516 - 8s - loss: 68415848.0000 - mse: 68415848.0000 - val_loss: 56990560.0000 - val_mse: 56990560.0000\n",
      "Epoch 89/1000\n",
      "6516/6516 - 8s - loss: 68687448.0000 - mse: 68687448.0000 - val_loss: 57448636.0000 - val_mse: 57448636.0000\n",
      "Epoch 90/1000\n",
      "6516/6516 - 8s - loss: 68124368.0000 - mse: 68124368.0000 - val_loss: 60938844.0000 - val_mse: 60938844.0000\n",
      "Epoch 91/1000\n",
      "6516/6516 - 9s - loss: 68027736.0000 - mse: 68027736.0000 - val_loss: 59994640.0000 - val_mse: 59994640.0000\n",
      "Epoch 92/1000\n",
      "6516/6516 - 13s - loss: 68255088.0000 - mse: 68255088.0000 - val_loss: 62705116.0000 - val_mse: 62705116.0000\n",
      "Epoch 93/1000\n",
      "6516/6516 - 9s - loss: 68557728.0000 - mse: 68557728.0000 - val_loss: 59012440.0000 - val_mse: 59012440.0000\n",
      "Epoch 94/1000\n",
      "6516/6516 - 9s - loss: 69047840.0000 - mse: 69047840.0000 - val_loss: 56467140.0000 - val_mse: 56467140.0000\n",
      "Epoch 95/1000\n",
      "6516/6516 - 9s - loss: 68058144.0000 - mse: 68058144.0000 - val_loss: 55780076.0000 - val_mse: 55780076.0000\n",
      "Epoch 96/1000\n",
      "6516/6516 - 14s - loss: 68729256.0000 - mse: 68729256.0000 - val_loss: 61427096.0000 - val_mse: 61427096.0000\n",
      "Epoch 97/1000\n",
      "6516/6516 - 17s - loss: 68065816.0000 - mse: 68065816.0000 - val_loss: 57819384.0000 - val_mse: 57819384.0000\n",
      "Epoch 98/1000\n",
      "6516/6516 - 13s - loss: 68532264.0000 - mse: 68532264.0000 - val_loss: 60610660.0000 - val_mse: 60610660.0000\n",
      "Epoch 99/1000\n",
      "6516/6516 - 12s - loss: 67814160.0000 - mse: 67814160.0000 - val_loss: 57928836.0000 - val_mse: 57928836.0000\n",
      "Epoch 100/1000\n",
      "6516/6516 - 12s - loss: 68002848.0000 - mse: 68002848.0000 - val_loss: 60945984.0000 - val_mse: 60945984.0000\n",
      "Epoch 101/1000\n",
      "6516/6516 - 12s - loss: 67904568.0000 - mse: 67904568.0000 - val_loss: 59118628.0000 - val_mse: 59118628.0000\n",
      "Epoch 102/1000\n",
      "6516/6516 - 12s - loss: 68644136.0000 - mse: 68644136.0000 - val_loss: 59292972.0000 - val_mse: 59292972.0000\n",
      "Epoch 103/1000\n",
      "6516/6516 - 12s - loss: 68494968.0000 - mse: 68494968.0000 - val_loss: 56067320.0000 - val_mse: 56067320.0000\n",
      "Epoch 104/1000\n",
      "6516/6516 - 12s - loss: 68770696.0000 - mse: 68770696.0000 - val_loss: 60015016.0000 - val_mse: 60015016.0000\n",
      "Epoch 105/1000\n",
      "6516/6516 - 12s - loss: 68779904.0000 - mse: 68779904.0000 - val_loss: 56669616.0000 - val_mse: 56669616.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3086147054696461"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 11s - loss: 81873408.0000 - mse: 81873408.0000 - val_loss: 64345600.0000 - val_mse: 64345600.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 10s - loss: 75029184.0000 - mse: 75029184.0000 - val_loss: 61714624.0000 - val_mse: 61714624.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 10s - loss: 72259048.0000 - mse: 72259048.0000 - val_loss: 62625388.0000 - val_mse: 62625388.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 10s - loss: 71621184.0000 - mse: 71621184.0000 - val_loss: 59781784.0000 - val_mse: 59781784.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 10s - loss: 71191664.0000 - mse: 71191664.0000 - val_loss: 59827980.0000 - val_mse: 59827980.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 12s - loss: 70548840.0000 - mse: 70548840.0000 - val_loss: 61645548.0000 - val_mse: 61645548.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 19s - loss: 69880440.0000 - mse: 69880440.0000 - val_loss: 59373468.0000 - val_mse: 59373468.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 13s - loss: 69906296.0000 - mse: 69906296.0000 - val_loss: 60025468.0000 - val_mse: 60025468.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 14s - loss: 69311536.0000 - mse: 69311536.0000 - val_loss: 58928756.0000 - val_mse: 58928756.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 15s - loss: 68624680.0000 - mse: 68624680.0000 - val_loss: 57085732.0000 - val_mse: 57085732.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 12s - loss: 68397216.0000 - mse: 68397216.0000 - val_loss: 57927204.0000 - val_mse: 57927204.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 14s - loss: 68363424.0000 - mse: 68363424.0000 - val_loss: 59507708.0000 - val_mse: 59507708.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 17s - loss: 68183800.0000 - mse: 68183800.0000 - val_loss: 59592992.0000 - val_mse: 59592992.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 29s - loss: 67887456.0000 - mse: 67887456.0000 - val_loss: 56876896.0000 - val_mse: 56876896.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 19s - loss: 67789632.0000 - mse: 67789632.0000 - val_loss: 56914248.0000 - val_mse: 56914248.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 13s - loss: 67695272.0000 - mse: 67695272.0000 - val_loss: 56013492.0000 - val_mse: 56013492.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 13s - loss: 67680808.0000 - mse: 67680808.0000 - val_loss: 57950844.0000 - val_mse: 57950844.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 15s - loss: 67572520.0000 - mse: 67572520.0000 - val_loss: 58409232.0000 - val_mse: 58409232.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 12s - loss: 67264072.0000 - mse: 67264072.0000 - val_loss: 59828092.0000 - val_mse: 59828092.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 15s - loss: 67034840.0000 - mse: 67034840.0000 - val_loss: 55704512.0000 - val_mse: 55704512.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 13s - loss: 67320824.0000 - mse: 67320824.0000 - val_loss: 59766240.0000 - val_mse: 59766240.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 14s - loss: 66721900.0000 - mse: 66721900.0000 - val_loss: 58558332.0000 - val_mse: 58558332.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 12s - loss: 67315416.0000 - mse: 67315416.0000 - val_loss: 58657336.0000 - val_mse: 58657336.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 12s - loss: 67139320.0000 - mse: 67139320.0000 - val_loss: 57312172.0000 - val_mse: 57312172.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 11s - loss: 66888664.0000 - mse: 66888664.0000 - val_loss: 55969340.0000 - val_mse: 55969340.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 12s - loss: 67088124.0000 - mse: 67088124.0000 - val_loss: 56924924.0000 - val_mse: 56924924.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 12s - loss: 67015416.0000 - mse: 67015416.0000 - val_loss: 57860224.0000 - val_mse: 57860224.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 12s - loss: 66972052.0000 - mse: 66972052.0000 - val_loss: 56887404.0000 - val_mse: 56887404.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 11s - loss: 67179352.0000 - mse: 67179352.0000 - val_loss: 54626348.0000 - val_mse: 54626348.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 12s - loss: 66783616.0000 - mse: 66783616.0000 - val_loss: 56482508.0000 - val_mse: 56482508.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 26s - loss: 66884836.0000 - mse: 66884836.0000 - val_loss: 56356488.0000 - val_mse: 56356488.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 16s - loss: 67169680.0000 - mse: 67169680.0000 - val_loss: 58715060.0000 - val_mse: 58715060.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 13s - loss: 66593016.0000 - mse: 66593016.0000 - val_loss: 58205772.0000 - val_mse: 58205772.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 18s - loss: 66695280.0000 - mse: 66695280.0000 - val_loss: 55593600.0000 - val_mse: 55593600.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 13s - loss: 66678136.0000 - mse: 66678136.0000 - val_loss: 57745428.0000 - val_mse: 57745428.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 13s - loss: 67046544.0000 - mse: 67046544.0000 - val_loss: 57208772.0000 - val_mse: 57208772.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 13s - loss: 66547804.0000 - mse: 66547804.0000 - val_loss: 56046368.0000 - val_mse: 56046368.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 13s - loss: 66648204.0000 - mse: 66648204.0000 - val_loss: 60205528.0000 - val_mse: 60205528.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 13s - loss: 66731788.0000 - mse: 66731788.0000 - val_loss: 57348148.0000 - val_mse: 57348148.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 13s - loss: 66554384.0000 - mse: 66554384.0000 - val_loss: 58428048.0000 - val_mse: 58428048.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 13s - loss: 66410120.0000 - mse: 66410120.0000 - val_loss: 57618948.0000 - val_mse: 57618948.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 13s - loss: 67179024.0000 - mse: 67179024.0000 - val_loss: 63123776.0000 - val_mse: 63123776.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 13s - loss: 66764708.0000 - mse: 66764708.0000 - val_loss: 56212704.0000 - val_mse: 56212704.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 13s - loss: 66605544.0000 - mse: 66605544.0000 - val_loss: 58802392.0000 - val_mse: 58802392.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 13s - loss: 67131056.0000 - mse: 67131056.0000 - val_loss: 59384860.0000 - val_mse: 59384860.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 13s - loss: 66716052.0000 - mse: 66716052.0000 - val_loss: 59117464.0000 - val_mse: 59117464.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 13s - loss: 66854796.0000 - mse: 66854796.0000 - val_loss: 60414348.0000 - val_mse: 60414348.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 13s - loss: 66457664.0000 - mse: 66457664.0000 - val_loss: 55370660.0000 - val_mse: 55370660.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 13s - loss: 67057884.0000 - mse: 67057884.0000 - val_loss: 58629132.0000 - val_mse: 58629132.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 13s - loss: 67100532.0000 - mse: 67100532.0000 - val_loss: 55569100.0000 - val_mse: 55569100.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 13s - loss: 67210928.0000 - mse: 67210928.0000 - val_loss: 55715112.0000 - val_mse: 55715112.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 13s - loss: 67767840.0000 - mse: 67767840.0000 - val_loss: 59076560.0000 - val_mse: 59076560.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 13s - loss: 67344376.0000 - mse: 67344376.0000 - val_loss: 55199748.0000 - val_mse: 55199748.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 13s - loss: 67719128.0000 - mse: 67719128.0000 - val_loss: 60188372.0000 - val_mse: 60188372.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 13s - loss: 67518272.0000 - mse: 67518272.0000 - val_loss: 55800520.0000 - val_mse: 55800520.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 13s - loss: 66840728.0000 - mse: 66840728.0000 - val_loss: 54809208.0000 - val_mse: 54809208.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 13s - loss: 67357176.0000 - mse: 67357176.0000 - val_loss: 61331716.0000 - val_mse: 61331716.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 12s - loss: 66677748.0000 - mse: 66677748.0000 - val_loss: 58706796.0000 - val_mse: 58706796.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 14s - loss: 66350656.0000 - mse: 66350656.0000 - val_loss: 56456188.0000 - val_mse: 56456188.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3111942636027799"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 11s - loss: 107373760.0000 - mse: 107373760.0000 - val_loss: 72973880.0000 - val_mse: 72973880.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 10s - loss: 83977184.0000 - mse: 83977184.0000 - val_loss: 69426896.0000 - val_mse: 69426896.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 14s - loss: 80898272.0000 - mse: 80898272.0000 - val_loss: 68604880.0000 - val_mse: 68604880.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 12s - loss: 79472568.0000 - mse: 79472568.0000 - val_loss: 67806312.0000 - val_mse: 67806312.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 10s - loss: 78404032.0000 - mse: 78404032.0000 - val_loss: 67090704.0000 - val_mse: 67090704.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 12s - loss: 77691016.0000 - mse: 77691016.0000 - val_loss: 66474000.0000 - val_mse: 66474000.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 14s - loss: 77554936.0000 - mse: 77554936.0000 - val_loss: 66633840.0000 - val_mse: 66633840.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 21s - loss: 77190592.0000 - mse: 77190592.0000 - val_loss: 66266068.0000 - val_mse: 66266068.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 15s - loss: 76577224.0000 - mse: 76577224.0000 - val_loss: 65972836.0000 - val_mse: 65972836.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 25s - loss: 76397816.0000 - mse: 76397816.0000 - val_loss: 64796536.0000 - val_mse: 64796536.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 22s - loss: 75907528.0000 - mse: 75907528.0000 - val_loss: 64711776.0000 - val_mse: 64711776.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 19s - loss: 75669944.0000 - mse: 75669944.0000 - val_loss: 64815568.0000 - val_mse: 64815568.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 13s - loss: 75150984.0000 - mse: 75150984.0000 - val_loss: 65306016.0000 - val_mse: 65306016.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 14s - loss: 74751352.0000 - mse: 74751352.0000 - val_loss: 63709704.0000 - val_mse: 63709704.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 12s - loss: 74462560.0000 - mse: 74462560.0000 - val_loss: 63774936.0000 - val_mse: 63774936.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 13s - loss: 74112712.0000 - mse: 74112712.0000 - val_loss: 64252664.0000 - val_mse: 64252664.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 12s - loss: 73806880.0000 - mse: 73806880.0000 - val_loss: 65020464.0000 - val_mse: 65020464.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 12s - loss: 73914440.0000 - mse: 73914440.0000 - val_loss: 63546780.0000 - val_mse: 63546780.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 11s - loss: 73578224.0000 - mse: 73578224.0000 - val_loss: 63961948.0000 - val_mse: 63961948.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 17s - loss: 73085048.0000 - mse: 73085048.0000 - val_loss: 63318664.0000 - val_mse: 63318664.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 13s - loss: 72903784.0000 - mse: 72903784.0000 - val_loss: 63207440.0000 - val_mse: 63207440.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 13s - loss: 73074136.0000 - mse: 73074136.0000 - val_loss: 63892748.0000 - val_mse: 63892748.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 11s - loss: 72715568.0000 - mse: 72715568.0000 - val_loss: 63136656.0000 - val_mse: 63136656.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 11s - loss: 72305832.0000 - mse: 72305832.0000 - val_loss: 63613832.0000 - val_mse: 63613832.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 13s - loss: 72517640.0000 - mse: 72517640.0000 - val_loss: 63000884.0000 - val_mse: 63000884.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 12s - loss: 72337896.0000 - mse: 72337896.0000 - val_loss: 63507684.0000 - val_mse: 63507684.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 20s - loss: 71928048.0000 - mse: 71928048.0000 - val_loss: 63750652.0000 - val_mse: 63750652.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 19s - loss: 71723600.0000 - mse: 71723600.0000 - val_loss: 62722912.0000 - val_mse: 62722912.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 14s - loss: 71525336.0000 - mse: 71525336.0000 - val_loss: 63399628.0000 - val_mse: 63399628.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 22s - loss: 71717576.0000 - mse: 71717576.0000 - val_loss: 63201148.0000 - val_mse: 63201148.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 18s - loss: 71627888.0000 - mse: 71627888.0000 - val_loss: 63611784.0000 - val_mse: 63611784.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 31s - loss: 71335024.0000 - mse: 71335024.0000 - val_loss: 63030120.0000 - val_mse: 63030120.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 28s - loss: 71327912.0000 - mse: 71327912.0000 - val_loss: 64046432.0000 - val_mse: 64046432.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 24s - loss: 71288832.0000 - mse: 71288832.0000 - val_loss: 62840832.0000 - val_mse: 62840832.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 15s - loss: 71087616.0000 - mse: 71087616.0000 - val_loss: 63258768.0000 - val_mse: 63258768.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 13s - loss: 70893288.0000 - mse: 70893288.0000 - val_loss: 63934772.0000 - val_mse: 63934772.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 12s - loss: 70816400.0000 - mse: 70816400.0000 - val_loss: 62572852.0000 - val_mse: 62572852.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 12s - loss: 71036056.0000 - mse: 71036056.0000 - val_loss: 63398628.0000 - val_mse: 63398628.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 12s - loss: 71090992.0000 - mse: 71090992.0000 - val_loss: 63269336.0000 - val_mse: 63269336.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 12s - loss: 70952200.0000 - mse: 70952200.0000 - val_loss: 63132768.0000 - val_mse: 63132768.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 12s - loss: 70693480.0000 - mse: 70693480.0000 - val_loss: 63439604.0000 - val_mse: 63439604.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 12s - loss: 70885080.0000 - mse: 70885080.0000 - val_loss: 62877280.0000 - val_mse: 62877280.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 12s - loss: 70407992.0000 - mse: 70407992.0000 - val_loss: 63369772.0000 - val_mse: 63369772.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 12s - loss: 70438464.0000 - mse: 70438464.0000 - val_loss: 63534652.0000 - val_mse: 63534652.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 12s - loss: 70380032.0000 - mse: 70380032.0000 - val_loss: 63078656.0000 - val_mse: 63078656.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 14s - loss: 70389384.0000 - mse: 70389384.0000 - val_loss: 62573736.0000 - val_mse: 62573736.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 13s - loss: 70417088.0000 - mse: 70417088.0000 - val_loss: 64680392.0000 - val_mse: 64680392.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 12s - loss: 70381424.0000 - mse: 70381424.0000 - val_loss: 63314896.0000 - val_mse: 63314896.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 18s - loss: 70403384.0000 - mse: 70403384.0000 - val_loss: 62587324.0000 - val_mse: 62587324.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 12s - loss: 70189872.0000 - mse: 70189872.0000 - val_loss: 63530264.0000 - val_mse: 63530264.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 11s - loss: 70145576.0000 - mse: 70145576.0000 - val_loss: 63425464.0000 - val_mse: 63425464.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 11s - loss: 70353976.0000 - mse: 70353976.0000 - val_loss: 63882088.0000 - val_mse: 63882088.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 11s - loss: 70227608.0000 - mse: 70227608.0000 - val_loss: 63924332.0000 - val_mse: 63924332.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 11s - loss: 69983264.0000 - mse: 69983264.0000 - val_loss: 63531612.0000 - val_mse: 63531612.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 13s - loss: 69778568.0000 - mse: 69778568.0000 - val_loss: 63839744.0000 - val_mse: 63839744.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 14s - loss: 69761848.0000 - mse: 69761848.0000 - val_loss: 63662220.0000 - val_mse: 63662220.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 13s - loss: 69804264.0000 - mse: 69804264.0000 - val_loss: 63642324.0000 - val_mse: 63642324.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 10s - loss: 69857952.0000 - mse: 69857952.0000 - val_loss: 63829056.0000 - val_mse: 63829056.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 10s - loss: 70037448.0000 - mse: 70037448.0000 - val_loss: 63135004.0000 - val_mse: 63135004.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 15s - loss: 69861944.0000 - mse: 69861944.0000 - val_loss: 63377952.0000 - val_mse: 63377952.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 19s - loss: 69477368.0000 - mse: 69477368.0000 - val_loss: 63715672.0000 - val_mse: 63715672.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 19s - loss: 69788352.0000 - mse: 69788352.0000 - val_loss: 62974288.0000 - val_mse: 62974288.0000\n",
      "Epoch 63/1000\n",
      "6516/6516 - 15s - loss: 69346320.0000 - mse: 69346320.0000 - val_loss: 63806028.0000 - val_mse: 63806028.0000\n",
      "Epoch 64/1000\n",
      "6516/6516 - 19s - loss: 69798664.0000 - mse: 69798664.0000 - val_loss: 63886672.0000 - val_mse: 63886672.0000\n",
      "Epoch 65/1000\n",
      "6516/6516 - 13s - loss: 69763064.0000 - mse: 69763064.0000 - val_loss: 63242352.0000 - val_mse: 63242352.0000\n",
      "Epoch 66/1000\n",
      "6516/6516 - 12s - loss: 69361832.0000 - mse: 69361832.0000 - val_loss: 63009864.0000 - val_mse: 63009864.0000\n",
      "Epoch 67/1000\n",
      "6516/6516 - 11s - loss: 69591848.0000 - mse: 69591848.0000 - val_loss: 64625812.0000 - val_mse: 64625812.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23973059253530726"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 19s - loss: 74038808.0000 - mse: 74038808.0000 - val_loss: 60734548.0000 - val_mse: 60734548.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 14s - loss: 70730568.0000 - mse: 70730568.0000 - val_loss: 63911076.0000 - val_mse: 63911076.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 15s - loss: 70390688.0000 - mse: 70390688.0000 - val_loss: 57225616.0000 - val_mse: 57225616.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 14s - loss: 69441520.0000 - mse: 69441520.0000 - val_loss: 57413392.0000 - val_mse: 57413392.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 14s - loss: 69656272.0000 - mse: 69656272.0000 - val_loss: 58552908.0000 - val_mse: 58552908.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 15s - loss: 68884096.0000 - mse: 68884096.0000 - val_loss: 57151060.0000 - val_mse: 57151060.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 15s - loss: 67920704.0000 - mse: 67920704.0000 - val_loss: 55252920.0000 - val_mse: 55252920.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 15s - loss: 67840848.0000 - mse: 67840848.0000 - val_loss: 61163976.0000 - val_mse: 61163976.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 10s - loss: 67289464.0000 - mse: 67289464.0000 - val_loss: 59799704.0000 - val_mse: 59799704.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 10s - loss: 67366536.0000 - mse: 67366536.0000 - val_loss: 55685084.0000 - val_mse: 55685084.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 11s - loss: 67791904.0000 - mse: 67791904.0000 - val_loss: 55234116.0000 - val_mse: 55234116.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 10s - loss: 66887104.0000 - mse: 66887104.0000 - val_loss: 57706816.0000 - val_mse: 57706816.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 10s - loss: 67867296.0000 - mse: 67867296.0000 - val_loss: 57924284.0000 - val_mse: 57924284.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 10s - loss: 67075076.0000 - mse: 67075076.0000 - val_loss: 59004244.0000 - val_mse: 59004244.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 10s - loss: 66723852.0000 - mse: 66723852.0000 - val_loss: 56632540.0000 - val_mse: 56632540.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 11s - loss: 67403672.0000 - mse: 67403672.0000 - val_loss: 55973444.0000 - val_mse: 55973444.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 11s - loss: 67458920.0000 - mse: 67458920.0000 - val_loss: 67565976.0000 - val_mse: 67565976.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 11s - loss: 66680096.0000 - mse: 66680096.0000 - val_loss: 53944372.0000 - val_mse: 53944372.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 12s - loss: 68658864.0000 - mse: 68658864.0000 - val_loss: 60726164.0000 - val_mse: 60726164.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 12s - loss: 67155256.0000 - mse: 67155256.0000 - val_loss: 58871716.0000 - val_mse: 58871716.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 10s - loss: 67182616.0000 - mse: 67182616.0000 - val_loss: 57573228.0000 - val_mse: 57573228.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 10s - loss: 66218844.0000 - mse: 66218844.0000 - val_loss: 63375648.0000 - val_mse: 63375648.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 11s - loss: 66673760.0000 - mse: 66673760.0000 - val_loss: 58914328.0000 - val_mse: 58914328.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 11s - loss: 66411148.0000 - mse: 66411148.0000 - val_loss: 58525184.0000 - val_mse: 58525184.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 11s - loss: 66561812.0000 - mse: 66561812.0000 - val_loss: 55121076.0000 - val_mse: 55121076.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 11s - loss: 66818836.0000 - mse: 66818836.0000 - val_loss: 55410520.0000 - val_mse: 55410520.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 11s - loss: 67494064.0000 - mse: 67494064.0000 - val_loss: 60998896.0000 - val_mse: 60998896.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 10s - loss: 66374440.0000 - mse: 66374440.0000 - val_loss: 57605328.0000 - val_mse: 57605328.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 11s - loss: 67157216.0000 - mse: 67157216.0000 - val_loss: 60689984.0000 - val_mse: 60689984.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 11s - loss: 67300992.0000 - mse: 67300992.0000 - val_loss: 61682792.0000 - val_mse: 61682792.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 11s - loss: 69024736.0000 - mse: 69024736.0000 - val_loss: 54479480.0000 - val_mse: 54479480.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 11s - loss: 68762000.0000 - mse: 68762000.0000 - val_loss: 59366412.0000 - val_mse: 59366412.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 12s - loss: 67585600.0000 - mse: 67585600.0000 - val_loss: 53309000.0000 - val_mse: 53309000.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 11s - loss: 66543928.0000 - mse: 66543928.0000 - val_loss: 55883440.0000 - val_mse: 55883440.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 10s - loss: 67293760.0000 - mse: 67293760.0000 - val_loss: 61685104.0000 - val_mse: 61685104.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 12s - loss: 66641484.0000 - mse: 66641484.0000 - val_loss: 58611556.0000 - val_mse: 58611556.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 10s - loss: 66607072.0000 - mse: 66607072.0000 - val_loss: 57737416.0000 - val_mse: 57737416.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 10s - loss: 65226356.0000 - mse: 65226356.0000 - val_loss: 54693928.0000 - val_mse: 54693928.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 11s - loss: 65098124.0000 - mse: 65098124.0000 - val_loss: 54961944.0000 - val_mse: 54961944.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 12s - loss: 65826704.0000 - mse: 65826704.0000 - val_loss: 58576324.0000 - val_mse: 58576324.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 11s - loss: 66421484.0000 - mse: 66421484.0000 - val_loss: 52872736.0000 - val_mse: 52872736.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 11s - loss: 64673536.0000 - mse: 64673536.0000 - val_loss: 55167792.0000 - val_mse: 55167792.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 11s - loss: 66980200.0000 - mse: 66980200.0000 - val_loss: 56462920.0000 - val_mse: 56462920.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 10s - loss: 65016944.0000 - mse: 65016944.0000 - val_loss: 57274816.0000 - val_mse: 57274816.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 11s - loss: 65397356.0000 - mse: 65397356.0000 - val_loss: 54434784.0000 - val_mse: 54434784.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 10s - loss: 65088512.0000 - mse: 65088512.0000 - val_loss: 56033288.0000 - val_mse: 56033288.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 11s - loss: 65701340.0000 - mse: 65701340.0000 - val_loss: 57347572.0000 - val_mse: 57347572.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 11s - loss: 66407816.0000 - mse: 66407816.0000 - val_loss: 55376816.0000 - val_mse: 55376816.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 11s - loss: 66063496.0000 - mse: 66063496.0000 - val_loss: 55282848.0000 - val_mse: 55282848.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 11s - loss: 66604212.0000 - mse: 66604212.0000 - val_loss: 55455032.0000 - val_mse: 55455032.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 11s - loss: 66591868.0000 - mse: 66591868.0000 - val_loss: 57327308.0000 - val_mse: 57327308.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 11s - loss: 66310128.0000 - mse: 66310128.0000 - val_loss: 57342708.0000 - val_mse: 57342708.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 11s - loss: 66661200.0000 - mse: 66661200.0000 - val_loss: 56224828.0000 - val_mse: 56224828.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 10s - loss: 67199272.0000 - mse: 67199272.0000 - val_loss: 54714828.0000 - val_mse: 54714828.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 10s - loss: 64588128.0000 - mse: 64588128.0000 - val_loss: 55370644.0000 - val_mse: 55370644.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 10s - loss: 64669424.0000 - mse: 64669424.0000 - val_loss: 53463936.0000 - val_mse: 53463936.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 12s - loss: 65921848.0000 - mse: 65921848.0000 - val_loss: 57929432.0000 - val_mse: 57929432.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 11s - loss: 67077172.0000 - mse: 67077172.0000 - val_loss: 53231964.0000 - val_mse: 53231964.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 10s - loss: 65422384.0000 - mse: 65422384.0000 - val_loss: 54193500.0000 - val_mse: 54193500.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 11s - loss: 65607020.0000 - mse: 65607020.0000 - val_loss: 60162920.0000 - val_mse: 60162920.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 11s - loss: 66265588.0000 - mse: 66265588.0000 - val_loss: 60638040.0000 - val_mse: 60638040.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 11s - loss: 65490528.0000 - mse: 65490528.0000 - val_loss: 52388076.0000 - val_mse: 52388076.0000\n",
      "Epoch 63/1000\n",
      "6516/6516 - 10s - loss: 65118960.0000 - mse: 65118960.0000 - val_loss: 52201324.0000 - val_mse: 52201324.0000\n",
      "Epoch 64/1000\n",
      "6516/6516 - 10s - loss: 64792104.0000 - mse: 64792104.0000 - val_loss: 53849916.0000 - val_mse: 53849916.0000\n",
      "Epoch 65/1000\n",
      "6516/6516 - 10s - loss: 65391172.0000 - mse: 65391172.0000 - val_loss: 53377372.0000 - val_mse: 53377372.0000\n",
      "Epoch 66/1000\n",
      "6516/6516 - 10s - loss: 65097532.0000 - mse: 65097532.0000 - val_loss: 60101312.0000 - val_mse: 60101312.0000\n",
      "Epoch 67/1000\n",
      "6516/6516 - 10s - loss: 64034584.0000 - mse: 64034584.0000 - val_loss: 66295128.0000 - val_mse: 66295128.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "6516/6516 - 10s - loss: 64938012.0000 - mse: 64938012.0000 - val_loss: 60235192.0000 - val_mse: 60235192.0000\n",
      "Epoch 69/1000\n",
      "6516/6516 - 10s - loss: 64597076.0000 - mse: 64597076.0000 - val_loss: 56373336.0000 - val_mse: 56373336.0000\n",
      "Epoch 70/1000\n",
      "6516/6516 - 10s - loss: 65899732.0000 - mse: 65899732.0000 - val_loss: 59754800.0000 - val_mse: 59754800.0000\n",
      "Epoch 71/1000\n",
      "6516/6516 - 10s - loss: 65412652.0000 - mse: 65412652.0000 - val_loss: 52677048.0000 - val_mse: 52677048.0000\n",
      "Epoch 72/1000\n",
      "6516/6516 - 11s - loss: 65253720.0000 - mse: 65253720.0000 - val_loss: 55173924.0000 - val_mse: 55173924.0000\n",
      "Epoch 73/1000\n",
      "6516/6516 - 11s - loss: 64552660.0000 - mse: 64552660.0000 - val_loss: 53863424.0000 - val_mse: 53863424.0000\n",
      "Epoch 74/1000\n",
      "6516/6516 - 10s - loss: 65659656.0000 - mse: 65659656.0000 - val_loss: 53665868.0000 - val_mse: 53665868.0000\n",
      "Epoch 75/1000\n",
      "6516/6516 - 11s - loss: 63933196.0000 - mse: 63933196.0000 - val_loss: 52468428.0000 - val_mse: 52468428.0000\n",
      "Epoch 76/1000\n",
      "6516/6516 - 11s - loss: 65334852.0000 - mse: 65334852.0000 - val_loss: 54849272.0000 - val_mse: 54849272.0000\n",
      "Epoch 77/1000\n",
      "6516/6516 - 10s - loss: 64188076.0000 - mse: 64188076.0000 - val_loss: 57399788.0000 - val_mse: 57399788.0000\n",
      "Epoch 78/1000\n",
      "6516/6516 - 10s - loss: 65546128.0000 - mse: 65546128.0000 - val_loss: 51874404.0000 - val_mse: 51874404.0000\n",
      "Epoch 79/1000\n",
      "6516/6516 - 11s - loss: 63090204.0000 - mse: 63090204.0000 - val_loss: 53238140.0000 - val_mse: 53238140.0000\n",
      "Epoch 80/1000\n",
      "6516/6516 - 11s - loss: 64377168.0000 - mse: 64377168.0000 - val_loss: 56105712.0000 - val_mse: 56105712.0000\n",
      "Epoch 81/1000\n",
      "6516/6516 - 10s - loss: 64038240.0000 - mse: 64038240.0000 - val_loss: 52993592.0000 - val_mse: 52993592.0000\n",
      "Epoch 82/1000\n",
      "6516/6516 - 10s - loss: 63174576.0000 - mse: 63174576.0000 - val_loss: 55267176.0000 - val_mse: 55267176.0000\n",
      "Epoch 83/1000\n",
      "6516/6516 - 10s - loss: 66114284.0000 - mse: 66114284.0000 - val_loss: 53285784.0000 - val_mse: 53285784.0000\n",
      "Epoch 84/1000\n",
      "6516/6516 - 10s - loss: 66019132.0000 - mse: 66019132.0000 - val_loss: 58472020.0000 - val_mse: 58472020.0000\n",
      "Epoch 85/1000\n",
      "6516/6516 - 10s - loss: 65674324.0000 - mse: 65674324.0000 - val_loss: 53847584.0000 - val_mse: 53847584.0000\n",
      "Epoch 86/1000\n",
      "6516/6516 - 10s - loss: 65832808.0000 - mse: 65832808.0000 - val_loss: 55353516.0000 - val_mse: 55353516.0000\n",
      "Epoch 87/1000\n",
      "6516/6516 - 11s - loss: 65921092.0000 - mse: 65921092.0000 - val_loss: 53672116.0000 - val_mse: 53672116.0000\n",
      "Epoch 88/1000\n",
      "6516/6516 - 10s - loss: 67801280.0000 - mse: 67801280.0000 - val_loss: 58326456.0000 - val_mse: 58326456.0000\n",
      "Epoch 89/1000\n",
      "6516/6516 - 11s - loss: 65961368.0000 - mse: 65961368.0000 - val_loss: 56967780.0000 - val_mse: 56967780.0000\n",
      "Epoch 90/1000\n",
      "6516/6516 - 10s - loss: 66244632.0000 - mse: 66244632.0000 - val_loss: 55406292.0000 - val_mse: 55406292.0000\n",
      "Epoch 91/1000\n",
      "6516/6516 - 10s - loss: 66541608.0000 - mse: 66541608.0000 - val_loss: 54425432.0000 - val_mse: 54425432.0000\n",
      "Epoch 92/1000\n",
      "6516/6516 - 10s - loss: 66535208.0000 - mse: 66535208.0000 - val_loss: 54947216.0000 - val_mse: 54947216.0000\n",
      "Epoch 93/1000\n",
      "6516/6516 - 11s - loss: 66566564.0000 - mse: 66566564.0000 - val_loss: 53651768.0000 - val_mse: 53651768.0000\n",
      "Epoch 94/1000\n",
      "6516/6516 - 10s - loss: 65384844.0000 - mse: 65384844.0000 - val_loss: 59457092.0000 - val_mse: 59457092.0000\n",
      "Epoch 95/1000\n",
      "6516/6516 - 10s - loss: 65231316.0000 - mse: 65231316.0000 - val_loss: 59270852.0000 - val_mse: 59270852.0000\n",
      "Epoch 96/1000\n",
      "6516/6516 - 10s - loss: 68844912.0000 - mse: 68844912.0000 - val_loss: 58678928.0000 - val_mse: 58678928.0000\n",
      "Epoch 97/1000\n",
      "6516/6516 - 12s - loss: 67157888.0000 - mse: 67157888.0000 - val_loss: 60340088.0000 - val_mse: 60340088.0000\n",
      "Epoch 98/1000\n",
      "6516/6516 - 10s - loss: 66312752.0000 - mse: 66312752.0000 - val_loss: 57753500.0000 - val_mse: 57753500.0000\n",
      "Epoch 99/1000\n",
      "6516/6516 - 11s - loss: 65583884.0000 - mse: 65583884.0000 - val_loss: 56416092.0000 - val_mse: 56416092.0000\n",
      "Epoch 100/1000\n",
      "6516/6516 - 10s - loss: 71073272.0000 - mse: 71073272.0000 - val_loss: 55572384.0000 - val_mse: 55572384.0000\n",
      "Epoch 101/1000\n",
      "6516/6516 - 10s - loss: 71549952.0000 - mse: 71549952.0000 - val_loss: 51558772.0000 - val_mse: 51558772.0000\n",
      "Epoch 102/1000\n",
      "6516/6516 - 10s - loss: 68227960.0000 - mse: 68227960.0000 - val_loss: 55822140.0000 - val_mse: 55822140.0000\n",
      "Epoch 103/1000\n",
      "6516/6516 - 11s - loss: 66606740.0000 - mse: 66606740.0000 - val_loss: 54951016.0000 - val_mse: 54951016.0000\n",
      "Epoch 104/1000\n",
      "6516/6516 - 10s - loss: 69743744.0000 - mse: 69743744.0000 - val_loss: 55157824.0000 - val_mse: 55157824.0000\n",
      "Epoch 105/1000\n",
      "6516/6516 - 10s - loss: 64501080.0000 - mse: 64501080.0000 - val_loss: 54566476.0000 - val_mse: 54566476.0000\n",
      "Epoch 106/1000\n",
      "6516/6516 - 11s - loss: 82561984.0000 - mse: 82561984.0000 - val_loss: 53229888.0000 - val_mse: 53229888.0000\n",
      "Epoch 107/1000\n",
      "6516/6516 - 11s - loss: 71713416.0000 - mse: 71713416.0000 - val_loss: 59777076.0000 - val_mse: 59777076.0000\n",
      "Epoch 108/1000\n",
      "6516/6516 - 11s - loss: 63640524.0000 - mse: 63640524.0000 - val_loss: 54529828.0000 - val_mse: 54529828.0000\n",
      "Epoch 109/1000\n",
      "6516/6516 - 10s - loss: 69424472.0000 - mse: 69424472.0000 - val_loss: 53714840.0000 - val_mse: 53714840.0000\n",
      "Epoch 110/1000\n",
      "6516/6516 - 11s - loss: 66271472.0000 - mse: 66271472.0000 - val_loss: 59877532.0000 - val_mse: 59877532.0000\n",
      "Epoch 111/1000\n",
      "6516/6516 - 11s - loss: 65522392.0000 - mse: 65522392.0000 - val_loss: 57541784.0000 - val_mse: 57541784.0000\n",
      "Epoch 112/1000\n",
      "6516/6516 - 11s - loss: 63251112.0000 - mse: 63251112.0000 - val_loss: 57571276.0000 - val_mse: 57571276.0000\n",
      "Epoch 113/1000\n",
      "6516/6516 - 12s - loss: 67125192.0000 - mse: 67125192.0000 - val_loss: 56036392.0000 - val_mse: 56036392.0000\n",
      "Epoch 114/1000\n",
      "6516/6516 - 11s - loss: 65725700.0000 - mse: 65725700.0000 - val_loss: 54435072.0000 - val_mse: 54435072.0000\n",
      "Epoch 115/1000\n",
      "6516/6516 - 10s - loss: 67890192.0000 - mse: 67890192.0000 - val_loss: 54616156.0000 - val_mse: 54616156.0000\n",
      "Epoch 116/1000\n",
      "6516/6516 - 10s - loss: 63277244.0000 - mse: 63277244.0000 - val_loss: 55298980.0000 - val_mse: 55298980.0000\n",
      "Epoch 117/1000\n",
      "6516/6516 - 11s - loss: 63673844.0000 - mse: 63673844.0000 - val_loss: 53567256.0000 - val_mse: 53567256.0000\n",
      "Epoch 118/1000\n",
      "6516/6516 - 11s - loss: 64229816.0000 - mse: 64229816.0000 - val_loss: 56300000.0000 - val_mse: 56300000.0000\n",
      "Epoch 119/1000\n",
      "6516/6516 - 11s - loss: 64905752.0000 - mse: 64905752.0000 - val_loss: 57121456.0000 - val_mse: 57121456.0000\n",
      "Epoch 120/1000\n",
      "6516/6516 - 11s - loss: 65890804.0000 - mse: 65890804.0000 - val_loss: 59146632.0000 - val_mse: 59146632.0000\n",
      "Epoch 121/1000\n",
      "6516/6516 - 11s - loss: 67370736.0000 - mse: 67370736.0000 - val_loss: 53263788.0000 - val_mse: 53263788.0000\n",
      "Epoch 122/1000\n",
      "6516/6516 - 10s - loss: 66710176.0000 - mse: 66710176.0000 - val_loss: 58323216.0000 - val_mse: 58323216.0000\n",
      "Epoch 123/1000\n",
      "6516/6516 - 10s - loss: 64774048.0000 - mse: 64774048.0000 - val_loss: 61498460.0000 - val_mse: 61498460.0000\n",
      "Epoch 124/1000\n",
      "6516/6516 - 11s - loss: 68026416.0000 - mse: 68026416.0000 - val_loss: 51994568.0000 - val_mse: 51994568.0000\n",
      "Epoch 125/1000\n",
      "6516/6516 - 10s - loss: 66522076.0000 - mse: 66522076.0000 - val_loss: 64022896.0000 - val_mse: 64022896.0000\n",
      "Epoch 126/1000\n",
      "6516/6516 - 10s - loss: 65156228.0000 - mse: 65156228.0000 - val_loss: 64171268.0000 - val_mse: 64171268.0000\n",
      "Epoch 127/1000\n",
      "6516/6516 - 10s - loss: 65272696.0000 - mse: 65272696.0000 - val_loss: 60329664.0000 - val_mse: 60329664.0000\n",
      "Epoch 128/1000\n",
      "6516/6516 - 10s - loss: 64892648.0000 - mse: 64892648.0000 - val_loss: 52769900.0000 - val_mse: 52769900.0000\n",
      "Epoch 129/1000\n",
      "6516/6516 - 11s - loss: 64788392.0000 - mse: 64788392.0000 - val_loss: 51327632.0000 - val_mse: 51327632.0000\n",
      "Epoch 130/1000\n",
      "6516/6516 - 12s - loss: 65597988.0000 - mse: 65597988.0000 - val_loss: 51439168.0000 - val_mse: 51439168.0000\n",
      "Epoch 131/1000\n",
      "6516/6516 - 10s - loss: 63194648.0000 - mse: 63194648.0000 - val_loss: 52809024.0000 - val_mse: 52809024.0000\n",
      "Epoch 132/1000\n",
      "6516/6516 - 11s - loss: 63847852.0000 - mse: 63847852.0000 - val_loss: 52162984.0000 - val_mse: 52162984.0000\n",
      "Epoch 133/1000\n",
      "6516/6516 - 11s - loss: 62824392.0000 - mse: 62824392.0000 - val_loss: 54138096.0000 - val_mse: 54138096.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000\n",
      "6516/6516 - 11s - loss: 63383220.0000 - mse: 63383220.0000 - val_loss: 51617524.0000 - val_mse: 51617524.0000\n",
      "Epoch 135/1000\n",
      "6516/6516 - 10s - loss: 62458712.0000 - mse: 62458712.0000 - val_loss: 59619404.0000 - val_mse: 59619404.0000\n",
      "Epoch 136/1000\n",
      "6516/6516 - 10s - loss: 62364696.0000 - mse: 62364696.0000 - val_loss: 55165772.0000 - val_mse: 55165772.0000\n",
      "Epoch 137/1000\n",
      "6516/6516 - 11s - loss: 62252752.0000 - mse: 62252752.0000 - val_loss: 54952916.0000 - val_mse: 54952916.0000\n",
      "Epoch 138/1000\n",
      "6516/6516 - 11s - loss: 62568692.0000 - mse: 62568692.0000 - val_loss: 66499952.0000 - val_mse: 66499952.0000\n",
      "Epoch 139/1000\n",
      "6516/6516 - 10s - loss: 62725672.0000 - mse: 62725672.0000 - val_loss: 52274772.0000 - val_mse: 52274772.0000\n",
      "Epoch 140/1000\n",
      "6516/6516 - 10s - loss: 61847380.0000 - mse: 61847380.0000 - val_loss: 53239684.0000 - val_mse: 53239684.0000\n",
      "Epoch 141/1000\n",
      "6516/6516 - 10s - loss: 62157448.0000 - mse: 62157448.0000 - val_loss: 61201280.0000 - val_mse: 61201280.0000\n",
      "Epoch 142/1000\n",
      "6516/6516 - 11s - loss: 62803028.0000 - mse: 62803028.0000 - val_loss: 51323420.0000 - val_mse: 51323420.0000\n",
      "Epoch 143/1000\n",
      "6516/6516 - 10s - loss: 61601524.0000 - mse: 61601524.0000 - val_loss: 60105780.0000 - val_mse: 60105780.0000\n",
      "Epoch 144/1000\n",
      "6516/6516 - 11s - loss: 62311640.0000 - mse: 62311640.0000 - val_loss: 53741584.0000 - val_mse: 53741584.0000\n",
      "Epoch 145/1000\n",
      "6516/6516 - 10s - loss: 62451348.0000 - mse: 62451348.0000 - val_loss: 51118920.0000 - val_mse: 51118920.0000\n",
      "Epoch 146/1000\n",
      "6516/6516 - 10s - loss: 62526876.0000 - mse: 62526876.0000 - val_loss: 54515568.0000 - val_mse: 54515568.0000\n",
      "Epoch 147/1000\n",
      "6516/6516 - 11s - loss: 62392676.0000 - mse: 62392676.0000 - val_loss: 53107436.0000 - val_mse: 53107436.0000\n",
      "Epoch 148/1000\n",
      "6516/6516 - 11s - loss: 62406116.0000 - mse: 62406116.0000 - val_loss: 52196668.0000 - val_mse: 52196668.0000\n",
      "Epoch 149/1000\n",
      "6516/6516 - 11s - loss: 62172620.0000 - mse: 62172620.0000 - val_loss: 57484396.0000 - val_mse: 57484396.0000\n",
      "Epoch 150/1000\n",
      "6516/6516 - 11s - loss: 61802748.0000 - mse: 61802748.0000 - val_loss: 57746964.0000 - val_mse: 57746964.0000\n",
      "Epoch 151/1000\n",
      "6516/6516 - 11s - loss: 61830668.0000 - mse: 61830668.0000 - val_loss: 53843520.0000 - val_mse: 53843520.0000\n",
      "Epoch 152/1000\n",
      "6516/6516 - 11s - loss: 61365064.0000 - mse: 61365064.0000 - val_loss: 51018164.0000 - val_mse: 51018164.0000\n",
      "Epoch 153/1000\n",
      "6516/6516 - 10s - loss: 61738708.0000 - mse: 61738708.0000 - val_loss: 55804680.0000 - val_mse: 55804680.0000\n",
      "Epoch 154/1000\n",
      "6516/6516 - 10s - loss: 61980504.0000 - mse: 61980504.0000 - val_loss: 57511272.0000 - val_mse: 57511272.0000\n",
      "Epoch 155/1000\n",
      "6516/6516 - 11s - loss: 60409472.0000 - mse: 60409472.0000 - val_loss: 55639192.0000 - val_mse: 55639192.0000\n",
      "Epoch 156/1000\n",
      "6516/6516 - 11s - loss: 60126892.0000 - mse: 60126892.0000 - val_loss: 59256620.0000 - val_mse: 59256620.0000\n",
      "Epoch 157/1000\n",
      "6516/6516 - 10s - loss: 62046356.0000 - mse: 62046356.0000 - val_loss: 52062024.0000 - val_mse: 52062024.0000\n",
      "Epoch 158/1000\n",
      "6516/6516 - 10s - loss: 62492004.0000 - mse: 62492004.0000 - val_loss: 53892796.0000 - val_mse: 53892796.0000\n",
      "Epoch 159/1000\n",
      "6516/6516 - 10s - loss: 62439384.0000 - mse: 62439384.0000 - val_loss: 55949624.0000 - val_mse: 55949624.0000\n",
      "Epoch 160/1000\n",
      "6516/6516 - 10s - loss: 61201600.0000 - mse: 61201600.0000 - val_loss: 54232640.0000 - val_mse: 54232640.0000\n",
      "Epoch 161/1000\n",
      "6516/6516 - 10s - loss: 61768152.0000 - mse: 61768152.0000 - val_loss: 54212980.0000 - val_mse: 54212980.0000\n",
      "Epoch 162/1000\n",
      "6516/6516 - 10s - loss: 61910896.0000 - mse: 61910896.0000 - val_loss: 51113600.0000 - val_mse: 51113600.0000\n",
      "Epoch 163/1000\n",
      "6516/6516 - 10s - loss: 60643988.0000 - mse: 60643988.0000 - val_loss: 55574984.0000 - val_mse: 55574984.0000\n",
      "Epoch 164/1000\n",
      "6516/6516 - 10s - loss: 60593128.0000 - mse: 60593128.0000 - val_loss: 55279604.0000 - val_mse: 55279604.0000\n",
      "Epoch 165/1000\n",
      "6516/6516 - 10s - loss: 60330332.0000 - mse: 60330332.0000 - val_loss: 53827816.0000 - val_mse: 53827816.0000\n",
      "Epoch 166/1000\n",
      "6516/6516 - 11s - loss: 59984000.0000 - mse: 59984000.0000 - val_loss: 52243620.0000 - val_mse: 52243620.0000\n",
      "Epoch 167/1000\n",
      "6516/6516 - 10s - loss: 62826760.0000 - mse: 62826760.0000 - val_loss: 51407312.0000 - val_mse: 51407312.0000\n",
      "Epoch 168/1000\n",
      "6516/6516 - 10s - loss: 64476560.0000 - mse: 64476560.0000 - val_loss: 53222000.0000 - val_mse: 53222000.0000\n",
      "Epoch 169/1000\n",
      "6516/6516 - 10s - loss: 61158700.0000 - mse: 61158700.0000 - val_loss: 54726532.0000 - val_mse: 54726532.0000\n",
      "Epoch 170/1000\n",
      "6516/6516 - 10s - loss: 60914096.0000 - mse: 60914096.0000 - val_loss: 54880732.0000 - val_mse: 54880732.0000\n",
      "Epoch 171/1000\n",
      "6516/6516 - 10s - loss: 61145940.0000 - mse: 61145940.0000 - val_loss: 55908896.0000 - val_mse: 55908896.0000\n",
      "Epoch 172/1000\n",
      "6516/6516 - 10s - loss: 61055540.0000 - mse: 61055540.0000 - val_loss: 55993576.0000 - val_mse: 55993576.0000\n",
      "Epoch 173/1000\n",
      "6516/6516 - 10s - loss: 60884948.0000 - mse: 60884948.0000 - val_loss: 52254032.0000 - val_mse: 52254032.0000\n",
      "Epoch 174/1000\n",
      "6516/6516 - 11s - loss: 60152680.0000 - mse: 60152680.0000 - val_loss: 54685132.0000 - val_mse: 54685132.0000\n",
      "Epoch 175/1000\n",
      "6516/6516 - 12s - loss: 60881468.0000 - mse: 60881468.0000 - val_loss: 54106056.0000 - val_mse: 54106056.0000\n",
      "Epoch 176/1000\n",
      "6516/6516 - 12s - loss: 60715276.0000 - mse: 60715276.0000 - val_loss: 54131840.0000 - val_mse: 54131840.0000\n",
      "Epoch 177/1000\n",
      "6516/6516 - 10s - loss: 60017112.0000 - mse: 60017112.0000 - val_loss: 53957520.0000 - val_mse: 53957520.0000\n",
      "Epoch 178/1000\n",
      "6516/6516 - 11s - loss: 59439412.0000 - mse: 59439412.0000 - val_loss: 52337836.0000 - val_mse: 52337836.0000\n",
      "Epoch 179/1000\n",
      "6516/6516 - 11s - loss: 59529932.0000 - mse: 59529932.0000 - val_loss: 59978264.0000 - val_mse: 59978264.0000\n",
      "Epoch 180/1000\n",
      "6516/6516 - 10s - loss: 61747016.0000 - mse: 61747016.0000 - val_loss: 51187636.0000 - val_mse: 51187636.0000\n",
      "Epoch 181/1000\n",
      "6516/6516 - 12s - loss: 61286436.0000 - mse: 61286436.0000 - val_loss: 53448412.0000 - val_mse: 53448412.0000\n",
      "Epoch 182/1000\n",
      "6516/6516 - 10s - loss: 60550312.0000 - mse: 60550312.0000 - val_loss: 59070712.0000 - val_mse: 59070712.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33042278290924043"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 16s - loss: 79133104.0000 - mse: 79133104.0000 - val_loss: 66920264.0000 - val_mse: 66920264.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 19s - loss: 75348880.0000 - mse: 75348880.0000 - val_loss: 58843432.0000 - val_mse: 58843432.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 15s - loss: 75054472.0000 - mse: 75054472.0000 - val_loss: 57371648.0000 - val_mse: 57371648.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 14s - loss: 73205760.0000 - mse: 73205760.0000 - val_loss: 59683844.0000 - val_mse: 59683844.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 21s - loss: 74256552.0000 - mse: 74256552.0000 - val_loss: 62500848.0000 - val_mse: 62500848.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 14s - loss: 71481336.0000 - mse: 71481336.0000 - val_loss: 58447820.0000 - val_mse: 58447820.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 13s - loss: 71974344.0000 - mse: 71974344.0000 - val_loss: 56663580.0000 - val_mse: 56663580.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 15s - loss: 71920632.0000 - mse: 71920632.0000 - val_loss: 65111404.0000 - val_mse: 65111404.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 14s - loss: 71415192.0000 - mse: 71415192.0000 - val_loss: 64149264.0000 - val_mse: 64149264.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 16s - loss: 71187048.0000 - mse: 71187048.0000 - val_loss: 54713548.0000 - val_mse: 54713548.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 22s - loss: 71497616.0000 - mse: 71497616.0000 - val_loss: 54627864.0000 - val_mse: 54627864.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 34s - loss: 70113560.0000 - mse: 70113560.0000 - val_loss: 60339956.0000 - val_mse: 60339956.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 30s - loss: 70824344.0000 - mse: 70824344.0000 - val_loss: 65729980.0000 - val_mse: 65729980.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 25s - loss: 69811912.0000 - mse: 69811912.0000 - val_loss: 57767008.0000 - val_mse: 57767008.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 30s - loss: 69564112.0000 - mse: 69564112.0000 - val_loss: 64332776.0000 - val_mse: 64332776.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 26s - loss: 69564584.0000 - mse: 69564584.0000 - val_loss: 56779380.0000 - val_mse: 56779380.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 21s - loss: 69296208.0000 - mse: 69296208.0000 - val_loss: 53826772.0000 - val_mse: 53826772.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 17s - loss: 69436056.0000 - mse: 69436056.0000 - val_loss: 58282248.0000 - val_mse: 58282248.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 19s - loss: 69532816.0000 - mse: 69532816.0000 - val_loss: 61455844.0000 - val_mse: 61455844.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 19s - loss: 68582968.0000 - mse: 68582968.0000 - val_loss: 59634432.0000 - val_mse: 59634432.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 24s - loss: 68768952.0000 - mse: 68768952.0000 - val_loss: 57796492.0000 - val_mse: 57796492.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 23s - loss: 67693160.0000 - mse: 67693160.0000 - val_loss: 58604020.0000 - val_mse: 58604020.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 25s - loss: 68146368.0000 - mse: 68146368.0000 - val_loss: 53730876.0000 - val_mse: 53730876.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 24s - loss: 67991192.0000 - mse: 67991192.0000 - val_loss: 54109944.0000 - val_mse: 54109944.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 28s - loss: 68291440.0000 - mse: 68291440.0000 - val_loss: 63282512.0000 - val_mse: 63282512.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 18s - loss: 68334328.0000 - mse: 68334328.0000 - val_loss: 55717268.0000 - val_mse: 55717268.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 17s - loss: 68176656.0000 - mse: 68176656.0000 - val_loss: 58818900.0000 - val_mse: 58818900.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 15s - loss: 67936680.0000 - mse: 67936680.0000 - val_loss: 57917836.0000 - val_mse: 57917836.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 14s - loss: 68479640.0000 - mse: 68479640.0000 - val_loss: 58616804.0000 - val_mse: 58616804.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 14s - loss: 66873796.0000 - mse: 66873796.0000 - val_loss: 57717840.0000 - val_mse: 57717840.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 14s - loss: 67661768.0000 - mse: 67661768.0000 - val_loss: 55583480.0000 - val_mse: 55583480.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 14s - loss: 66949856.0000 - mse: 66949856.0000 - val_loss: 57836852.0000 - val_mse: 57836852.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 14s - loss: 68048384.0000 - mse: 68048384.0000 - val_loss: 53886460.0000 - val_mse: 53886460.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 14s - loss: 67154080.0000 - mse: 67154080.0000 - val_loss: 57331092.0000 - val_mse: 57331092.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 14s - loss: 66804716.0000 - mse: 66804716.0000 - val_loss: 57123800.0000 - val_mse: 57123800.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 14s - loss: 66965880.0000 - mse: 66965880.0000 - val_loss: 59287832.0000 - val_mse: 59287832.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 13s - loss: 67642776.0000 - mse: 67642776.0000 - val_loss: 52612848.0000 - val_mse: 52612848.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 14s - loss: 67880976.0000 - mse: 67880976.0000 - val_loss: 54227772.0000 - val_mse: 54227772.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 14s - loss: 66245704.0000 - mse: 66245704.0000 - val_loss: 56446280.0000 - val_mse: 56446280.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 15s - loss: 66668520.0000 - mse: 66668520.0000 - val_loss: 56219416.0000 - val_mse: 56219416.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 15s - loss: 66779460.0000 - mse: 66779460.0000 - val_loss: 53082788.0000 - val_mse: 53082788.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 15s - loss: 65512000.0000 - mse: 65512000.0000 - val_loss: 58771844.0000 - val_mse: 58771844.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 14s - loss: 67245696.0000 - mse: 67245696.0000 - val_loss: 57519696.0000 - val_mse: 57519696.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 14s - loss: 66471988.0000 - mse: 66471988.0000 - val_loss: 54589312.0000 - val_mse: 54589312.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 14s - loss: 66861120.0000 - mse: 66861120.0000 - val_loss: 55170332.0000 - val_mse: 55170332.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 14s - loss: 66722304.0000 - mse: 66722304.0000 - val_loss: 61263616.0000 - val_mse: 61263616.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 14s - loss: 66387856.0000 - mse: 66387856.0000 - val_loss: 52287972.0000 - val_mse: 52287972.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 14s - loss: 66143120.0000 - mse: 66143120.0000 - val_loss: 56147724.0000 - val_mse: 56147724.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 14s - loss: 65541380.0000 - mse: 65541380.0000 - val_loss: 53618900.0000 - val_mse: 53618900.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 14s - loss: 66080320.0000 - mse: 66080320.0000 - val_loss: 57547620.0000 - val_mse: 57547620.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 14s - loss: 65752816.0000 - mse: 65752816.0000 - val_loss: 53832672.0000 - val_mse: 53832672.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 14s - loss: 66512408.0000 - mse: 66512408.0000 - val_loss: 54595140.0000 - val_mse: 54595140.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 14s - loss: 65717196.0000 - mse: 65717196.0000 - val_loss: 56943420.0000 - val_mse: 56943420.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 14s - loss: 66513456.0000 - mse: 66513456.0000 - val_loss: 52729332.0000 - val_mse: 52729332.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 14s - loss: 65770952.0000 - mse: 65770952.0000 - val_loss: 56126024.0000 - val_mse: 56126024.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 14s - loss: 64926888.0000 - mse: 64926888.0000 - val_loss: 57692376.0000 - val_mse: 57692376.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 14s - loss: 65955152.0000 - mse: 65955152.0000 - val_loss: 55562920.0000 - val_mse: 55562920.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 14s - loss: 65210080.0000 - mse: 65210080.0000 - val_loss: 52250208.0000 - val_mse: 52250208.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 13s - loss: 65200216.0000 - mse: 65200216.0000 - val_loss: 52057900.0000 - val_mse: 52057900.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 13s - loss: 65143724.0000 - mse: 65143724.0000 - val_loss: 52658444.0000 - val_mse: 52658444.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 13s - loss: 65305120.0000 - mse: 65305120.0000 - val_loss: 56447148.0000 - val_mse: 56447148.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 13s - loss: 66070976.0000 - mse: 66070976.0000 - val_loss: 55616956.0000 - val_mse: 55616956.0000\n",
      "Epoch 63/1000\n",
      "6516/6516 - 13s - loss: 64854420.0000 - mse: 64854420.0000 - val_loss: 56240796.0000 - val_mse: 56240796.0000\n",
      "Epoch 64/1000\n",
      "6516/6516 - 13s - loss: 65167404.0000 - mse: 65167404.0000 - val_loss: 55130896.0000 - val_mse: 55130896.0000\n",
      "Epoch 65/1000\n",
      "6516/6516 - 13s - loss: 64929936.0000 - mse: 64929936.0000 - val_loss: 56066840.0000 - val_mse: 56066840.0000\n",
      "Epoch 66/1000\n",
      "6516/6516 - 15s - loss: 65096484.0000 - mse: 65096484.0000 - val_loss: 51443704.0000 - val_mse: 51443704.0000\n",
      "Epoch 67/1000\n",
      "6516/6516 - 13s - loss: 65287348.0000 - mse: 65287348.0000 - val_loss: 57393216.0000 - val_mse: 57393216.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "6516/6516 - 14s - loss: 65775012.0000 - mse: 65775012.0000 - val_loss: 58549532.0000 - val_mse: 58549532.0000\n",
      "Epoch 69/1000\n",
      "6516/6516 - 14s - loss: 65302460.0000 - mse: 65302460.0000 - val_loss: 54602424.0000 - val_mse: 54602424.0000\n",
      "Epoch 70/1000\n",
      "6516/6516 - 14s - loss: 64802040.0000 - mse: 64802040.0000 - val_loss: 55655276.0000 - val_mse: 55655276.0000\n",
      "Epoch 71/1000\n",
      "6516/6516 - 13s - loss: 64830012.0000 - mse: 64830012.0000 - val_loss: 51408204.0000 - val_mse: 51408204.0000\n",
      "Epoch 72/1000\n",
      "6516/6516 - 13s - loss: 66285488.0000 - mse: 66285488.0000 - val_loss: 52825840.0000 - val_mse: 52825840.0000\n",
      "Epoch 73/1000\n",
      "6516/6516 - 13s - loss: 65283324.0000 - mse: 65283324.0000 - val_loss: 52227004.0000 - val_mse: 52227004.0000\n",
      "Epoch 74/1000\n",
      "6516/6516 - 14s - loss: 64779484.0000 - mse: 64779484.0000 - val_loss: 54627576.0000 - val_mse: 54627576.0000\n",
      "Epoch 75/1000\n",
      "6516/6516 - 13s - loss: 64737148.0000 - mse: 64737148.0000 - val_loss: 58197648.0000 - val_mse: 58197648.0000\n",
      "Epoch 76/1000\n",
      "6516/6516 - 13s - loss: 64816944.0000 - mse: 64816944.0000 - val_loss: 56563340.0000 - val_mse: 56563340.0000\n",
      "Epoch 77/1000\n",
      "6516/6516 - 13s - loss: 65263528.0000 - mse: 65263528.0000 - val_loss: 58509468.0000 - val_mse: 58509468.0000\n",
      "Epoch 78/1000\n",
      "6516/6516 - 13s - loss: 65087052.0000 - mse: 65087052.0000 - val_loss: 54362928.0000 - val_mse: 54362928.0000\n",
      "Epoch 79/1000\n",
      "6516/6516 - 13s - loss: 64583660.0000 - mse: 64583660.0000 - val_loss: 52377616.0000 - val_mse: 52377616.0000\n",
      "Epoch 80/1000\n",
      "6516/6516 - 13s - loss: 65662492.0000 - mse: 65662492.0000 - val_loss: 57038232.0000 - val_mse: 57038232.0000\n",
      "Epoch 81/1000\n",
      "6516/6516 - 13s - loss: 64552948.0000 - mse: 64552948.0000 - val_loss: 63503556.0000 - val_mse: 63503556.0000\n",
      "Epoch 82/1000\n",
      "6516/6516 - 13s - loss: 64597816.0000 - mse: 64597816.0000 - val_loss: 58020908.0000 - val_mse: 58020908.0000\n",
      "Epoch 83/1000\n",
      "6516/6516 - 13s - loss: 63930560.0000 - mse: 63930560.0000 - val_loss: 52181136.0000 - val_mse: 52181136.0000\n",
      "Epoch 84/1000\n",
      "6516/6516 - 13s - loss: 63541116.0000 - mse: 63541116.0000 - val_loss: 53610264.0000 - val_mse: 53610264.0000\n",
      "Epoch 85/1000\n",
      "6516/6516 - 13s - loss: 64786204.0000 - mse: 64786204.0000 - val_loss: 55958752.0000 - val_mse: 55958752.0000\n",
      "Epoch 86/1000\n",
      "6516/6516 - 13s - loss: 64391468.0000 - mse: 64391468.0000 - val_loss: 60342492.0000 - val_mse: 60342492.0000\n",
      "Epoch 87/1000\n",
      "6516/6516 - 13s - loss: 64306728.0000 - mse: 64306728.0000 - val_loss: 56041224.0000 - val_mse: 56041224.0000\n",
      "Epoch 88/1000\n",
      "6516/6516 - 13s - loss: 64621644.0000 - mse: 64621644.0000 - val_loss: 59501736.0000 - val_mse: 59501736.0000\n",
      "Epoch 89/1000\n",
      "6516/6516 - 14s - loss: 64642328.0000 - mse: 64642328.0000 - val_loss: 53803404.0000 - val_mse: 53803404.0000\n",
      "Epoch 90/1000\n",
      "6516/6516 - 13s - loss: 64447204.0000 - mse: 64447204.0000 - val_loss: 57420720.0000 - val_mse: 57420720.0000\n",
      "Epoch 91/1000\n",
      "6516/6516 - 13s - loss: 63685584.0000 - mse: 63685584.0000 - val_loss: 51385520.0000 - val_mse: 51385520.0000\n",
      "Epoch 92/1000\n",
      "6516/6516 - 13s - loss: 64632816.0000 - mse: 64632816.0000 - val_loss: 53156532.0000 - val_mse: 53156532.0000\n",
      "Epoch 93/1000\n",
      "6516/6516 - 13s - loss: 63574436.0000 - mse: 63574436.0000 - val_loss: 57147848.0000 - val_mse: 57147848.0000\n",
      "Epoch 94/1000\n",
      "6516/6516 - 13s - loss: 64360928.0000 - mse: 64360928.0000 - val_loss: 51544360.0000 - val_mse: 51544360.0000\n",
      "Epoch 95/1000\n",
      "6516/6516 - 13s - loss: 64357004.0000 - mse: 64357004.0000 - val_loss: 53374140.0000 - val_mse: 53374140.0000\n",
      "Epoch 96/1000\n",
      "6516/6516 - 13s - loss: 63761000.0000 - mse: 63761000.0000 - val_loss: 60189656.0000 - val_mse: 60189656.0000\n",
      "Epoch 97/1000\n",
      "6516/6516 - 13s - loss: 63909116.0000 - mse: 63909116.0000 - val_loss: 53235052.0000 - val_mse: 53235052.0000\n",
      "Epoch 98/1000\n",
      "6516/6516 - 13s - loss: 65120796.0000 - mse: 65120796.0000 - val_loss: 51414680.0000 - val_mse: 51414680.0000\n",
      "Epoch 99/1000\n",
      "6516/6516 - 13s - loss: 64708972.0000 - mse: 64708972.0000 - val_loss: 50998076.0000 - val_mse: 50998076.0000\n",
      "Epoch 100/1000\n",
      "6516/6516 - 13s - loss: 65061524.0000 - mse: 65061524.0000 - val_loss: 58017472.0000 - val_mse: 58017472.0000\n",
      "Epoch 101/1000\n",
      "6516/6516 - 13s - loss: 64342780.0000 - mse: 64342780.0000 - val_loss: 53104880.0000 - val_mse: 53104880.0000\n",
      "Epoch 102/1000\n",
      "6516/6516 - 13s - loss: 64134836.0000 - mse: 64134836.0000 - val_loss: 60190988.0000 - val_mse: 60190988.0000\n",
      "Epoch 103/1000\n",
      "6516/6516 - 13s - loss: 63145740.0000 - mse: 63145740.0000 - val_loss: 53345792.0000 - val_mse: 53345792.0000\n",
      "Epoch 104/1000\n",
      "6516/6516 - 13s - loss: 63275396.0000 - mse: 63275396.0000 - val_loss: 50356252.0000 - val_mse: 50356252.0000\n",
      "Epoch 105/1000\n",
      "6516/6516 - 13s - loss: 64173016.0000 - mse: 64173016.0000 - val_loss: 50944968.0000 - val_mse: 50944968.0000\n",
      "Epoch 106/1000\n",
      "6516/6516 - 13s - loss: 65421132.0000 - mse: 65421132.0000 - val_loss: 54204612.0000 - val_mse: 54204612.0000\n",
      "Epoch 107/1000\n",
      "6516/6516 - 13s - loss: 63877968.0000 - mse: 63877968.0000 - val_loss: 55895692.0000 - val_mse: 55895692.0000\n",
      "Epoch 108/1000\n",
      "6516/6516 - 13s - loss: 64286636.0000 - mse: 64286636.0000 - val_loss: 54001492.0000 - val_mse: 54001492.0000\n",
      "Epoch 109/1000\n",
      "6516/6516 - 13s - loss: 64375756.0000 - mse: 64375756.0000 - val_loss: 50969552.0000 - val_mse: 50969552.0000\n",
      "Epoch 110/1000\n",
      "6516/6516 - 13s - loss: 63783892.0000 - mse: 63783892.0000 - val_loss: 54768784.0000 - val_mse: 54768784.0000\n",
      "Epoch 111/1000\n",
      "6516/6516 - 13s - loss: 63303712.0000 - mse: 63303712.0000 - val_loss: 54747620.0000 - val_mse: 54747620.0000\n",
      "Epoch 112/1000\n",
      "6516/6516 - 13s - loss: 63622944.0000 - mse: 63622944.0000 - val_loss: 50759596.0000 - val_mse: 50759596.0000\n",
      "Epoch 113/1000\n",
      "6516/6516 - 13s - loss: 63198940.0000 - mse: 63198940.0000 - val_loss: 51228184.0000 - val_mse: 51228184.0000\n",
      "Epoch 114/1000\n",
      "6516/6516 - 13s - loss: 63213508.0000 - mse: 63213508.0000 - val_loss: 53871984.0000 - val_mse: 53871984.0000\n",
      "Epoch 115/1000\n",
      "6516/6516 - 14s - loss: 63684216.0000 - mse: 63684216.0000 - val_loss: 54491904.0000 - val_mse: 54491904.0000\n",
      "Epoch 116/1000\n",
      "6516/6516 - 13s - loss: 63092856.0000 - mse: 63092856.0000 - val_loss: 57155816.0000 - val_mse: 57155816.0000\n",
      "Epoch 117/1000\n",
      "6516/6516 - 13s - loss: 64218748.0000 - mse: 64218748.0000 - val_loss: 50602504.0000 - val_mse: 50602504.0000\n",
      "Epoch 118/1000\n",
      "6516/6516 - 13s - loss: 63836472.0000 - mse: 63836472.0000 - val_loss: 52703260.0000 - val_mse: 52703260.0000\n",
      "Epoch 119/1000\n",
      "6516/6516 - 13s - loss: 63418544.0000 - mse: 63418544.0000 - val_loss: 54219244.0000 - val_mse: 54219244.0000\n",
      "Epoch 120/1000\n",
      "6516/6516 - 13s - loss: 63192392.0000 - mse: 63192392.0000 - val_loss: 56282944.0000 - val_mse: 56282944.0000\n",
      "Epoch 121/1000\n",
      "6516/6516 - 13s - loss: 63429764.0000 - mse: 63429764.0000 - val_loss: 60163188.0000 - val_mse: 60163188.0000\n",
      "Epoch 122/1000\n",
      "6516/6516 - 13s - loss: 63792596.0000 - mse: 63792596.0000 - val_loss: 54374992.0000 - val_mse: 54374992.0000\n",
      "Epoch 123/1000\n",
      "6516/6516 - 13s - loss: 63853552.0000 - mse: 63853552.0000 - val_loss: 53468580.0000 - val_mse: 53468580.0000\n",
      "Epoch 124/1000\n",
      "6516/6516 - 13s - loss: 63639412.0000 - mse: 63639412.0000 - val_loss: 54528416.0000 - val_mse: 54528416.0000\n",
      "Epoch 125/1000\n",
      "6516/6516 - 13s - loss: 63911776.0000 - mse: 63911776.0000 - val_loss: 52394960.0000 - val_mse: 52394960.0000\n",
      "Epoch 126/1000\n",
      "6516/6516 - 13s - loss: 63333764.0000 - mse: 63333764.0000 - val_loss: 57251596.0000 - val_mse: 57251596.0000\n",
      "Epoch 127/1000\n",
      "6516/6516 - 13s - loss: 63490048.0000 - mse: 63490048.0000 - val_loss: 51094672.0000 - val_mse: 51094672.0000\n",
      "Epoch 128/1000\n",
      "6516/6516 - 13s - loss: 62863612.0000 - mse: 62863612.0000 - val_loss: 56970780.0000 - val_mse: 56970780.0000\n",
      "Epoch 129/1000\n",
      "6516/6516 - 13s - loss: 63848036.0000 - mse: 63848036.0000 - val_loss: 53138496.0000 - val_mse: 53138496.0000\n",
      "Epoch 130/1000\n",
      "6516/6516 - 13s - loss: 64342240.0000 - mse: 64342240.0000 - val_loss: 50869120.0000 - val_mse: 50869120.0000\n",
      "Epoch 131/1000\n",
      "6516/6516 - 13s - loss: 63442712.0000 - mse: 63442712.0000 - val_loss: 52831684.0000 - val_mse: 52831684.0000\n",
      "Epoch 132/1000\n",
      "6516/6516 - 13s - loss: 63758636.0000 - mse: 63758636.0000 - val_loss: 51312976.0000 - val_mse: 51312976.0000\n",
      "Epoch 133/1000\n",
      "6516/6516 - 13s - loss: 63782940.0000 - mse: 63782940.0000 - val_loss: 52418112.0000 - val_mse: 52418112.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000\n",
      "6516/6516 - 13s - loss: 63621796.0000 - mse: 63621796.0000 - val_loss: 51927944.0000 - val_mse: 51927944.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3580607784339288"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 20s - loss: 83251928.0000 - mse: 83251928.0000 - val_loss: 59846404.0000 - val_mse: 59846404.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 16s - loss: 76937880.0000 - mse: 76937880.0000 - val_loss: 58635016.0000 - val_mse: 58635016.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 21s - loss: 74679032.0000 - mse: 74679032.0000 - val_loss: 70198480.0000 - val_mse: 70198480.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 25s - loss: 73551912.0000 - mse: 73551912.0000 - val_loss: 67234608.0000 - val_mse: 67234608.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 18s - loss: 72394184.0000 - mse: 72394184.0000 - val_loss: 61831216.0000 - val_mse: 61831216.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 17s - loss: 73623144.0000 - mse: 73623144.0000 - val_loss: 60995092.0000 - val_mse: 60995092.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 16s - loss: 72622696.0000 - mse: 72622696.0000 - val_loss: 61996620.0000 - val_mse: 61996620.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 18s - loss: 71982536.0000 - mse: 71982536.0000 - val_loss: 60050456.0000 - val_mse: 60050456.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 16s - loss: 71107736.0000 - mse: 71107736.0000 - val_loss: 65244384.0000 - val_mse: 65244384.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 15s - loss: 71843384.0000 - mse: 71843384.0000 - val_loss: 60840100.0000 - val_mse: 60840100.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 14s - loss: 69789112.0000 - mse: 69789112.0000 - val_loss: 57090092.0000 - val_mse: 57090092.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 14s - loss: 71203672.0000 - mse: 71203672.0000 - val_loss: 62605136.0000 - val_mse: 62605136.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 15s - loss: 70475448.0000 - mse: 70475448.0000 - val_loss: 60309656.0000 - val_mse: 60309656.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 15s - loss: 71099728.0000 - mse: 71099728.0000 - val_loss: 54891784.0000 - val_mse: 54891784.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 15s - loss: 70170488.0000 - mse: 70170488.0000 - val_loss: 58520516.0000 - val_mse: 58520516.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 16s - loss: 69143728.0000 - mse: 69143728.0000 - val_loss: 63754380.0000 - val_mse: 63754380.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 18s - loss: 70076384.0000 - mse: 70076384.0000 - val_loss: 61027252.0000 - val_mse: 61027252.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 18s - loss: 69326024.0000 - mse: 69326024.0000 - val_loss: 56910224.0000 - val_mse: 56910224.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 17s - loss: 69577064.0000 - mse: 69577064.0000 - val_loss: 59063280.0000 - val_mse: 59063280.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 16s - loss: 69718296.0000 - mse: 69718296.0000 - val_loss: 58961956.0000 - val_mse: 58961956.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 16s - loss: 68343744.0000 - mse: 68343744.0000 - val_loss: 62084568.0000 - val_mse: 62084568.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 15s - loss: 69672440.0000 - mse: 69672440.0000 - val_loss: 57824360.0000 - val_mse: 57824360.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 15s - loss: 68879656.0000 - mse: 68879656.0000 - val_loss: 63888008.0000 - val_mse: 63888008.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 15s - loss: 69551776.0000 - mse: 69551776.0000 - val_loss: 58024360.0000 - val_mse: 58024360.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 15s - loss: 70448904.0000 - mse: 70448904.0000 - val_loss: 55940352.0000 - val_mse: 55940352.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 15s - loss: 69837240.0000 - mse: 69837240.0000 - val_loss: 56800712.0000 - val_mse: 56800712.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 15s - loss: 71548872.0000 - mse: 71548872.0000 - val_loss: 54350364.0000 - val_mse: 54350364.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 15s - loss: 71117584.0000 - mse: 71117584.0000 - val_loss: 58697340.0000 - val_mse: 58697340.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 16s - loss: 71019904.0000 - mse: 71019904.0000 - val_loss: 59872724.0000 - val_mse: 59872724.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 15s - loss: 71538208.0000 - mse: 71538208.0000 - val_loss: 61128560.0000 - val_mse: 61128560.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 15s - loss: 70341504.0000 - mse: 70341504.0000 - val_loss: 66938948.0000 - val_mse: 66938948.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 24s - loss: 70196216.0000 - mse: 70196216.0000 - val_loss: 60215024.0000 - val_mse: 60215024.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 21s - loss: 70220120.0000 - mse: 70220120.0000 - val_loss: 65080212.0000 - val_mse: 65080212.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 20s - loss: 71709536.0000 - mse: 71709536.0000 - val_loss: 56711812.0000 - val_mse: 56711812.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 20s - loss: 72113360.0000 - mse: 72113360.0000 - val_loss: 60543948.0000 - val_mse: 60543948.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 20s - loss: 71772784.0000 - mse: 71772784.0000 - val_loss: 61317068.0000 - val_mse: 61317068.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 17s - loss: 72685720.0000 - mse: 72685720.0000 - val_loss: 62787476.0000 - val_mse: 62787476.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 17s - loss: 73653608.0000 - mse: 73653608.0000 - val_loss: 64781912.0000 - val_mse: 64781912.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 16s - loss: 74676192.0000 - mse: 74676192.0000 - val_loss: 60359108.0000 - val_mse: 60359108.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 14s - loss: 73508768.0000 - mse: 73508768.0000 - val_loss: 57560372.0000 - val_mse: 57560372.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 17s - loss: 74478272.0000 - mse: 74478272.0000 - val_loss: 62695160.0000 - val_mse: 62695160.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 18s - loss: 73691920.0000 - mse: 73691920.0000 - val_loss: 62769748.0000 - val_mse: 62769748.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 14s - loss: 74866280.0000 - mse: 74866280.0000 - val_loss: 64205620.0000 - val_mse: 64205620.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 16s - loss: 75995736.0000 - mse: 75995736.0000 - val_loss: 64012320.0000 - val_mse: 64012320.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 14s - loss: 75941728.0000 - mse: 75941728.0000 - val_loss: 62882332.0000 - val_mse: 62882332.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 14s - loss: 76317120.0000 - mse: 76317120.0000 - val_loss: 67680256.0000 - val_mse: 67680256.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 14s - loss: 76490728.0000 - mse: 76490728.0000 - val_loss: 66490024.0000 - val_mse: 66490024.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 14s - loss: 76774248.0000 - mse: 76774248.0000 - val_loss: 66092576.0000 - val_mse: 66092576.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 15s - loss: 77114216.0000 - mse: 77114216.0000 - val_loss: 66914296.0000 - val_mse: 66914296.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 19s - loss: 76790488.0000 - mse: 76790488.0000 - val_loss: 64830316.0000 - val_mse: 64830316.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 20s - loss: 76282648.0000 - mse: 76282648.0000 - val_loss: 65963108.0000 - val_mse: 65963108.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 17s - loss: 78141152.0000 - mse: 78141152.0000 - val_loss: 67048160.0000 - val_mse: 67048160.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 15s - loss: 77665960.0000 - mse: 77665960.0000 - val_loss: 66978404.0000 - val_mse: 66978404.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 15s - loss: 77577552.0000 - mse: 77577552.0000 - val_loss: 66612400.0000 - val_mse: 66612400.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 15s - loss: 79825760.0000 - mse: 79825760.0000 - val_loss: 72245728.0000 - val_mse: 72245728.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 17s - loss: 88461808.0000 - mse: 88461808.0000 - val_loss: 78896224.0000 - val_mse: 78896224.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 19s - loss: 98891680.0000 - mse: 98891680.0000 - val_loss: 91408136.0000 - val_mse: 91408136.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.2, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31868096763044895"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 16s - loss: 84152584.0000 - mse: 84152584.0000 - val_loss: 81787496.0000 - val_mse: 81787496.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 18s - loss: 80359768.0000 - mse: 80359768.0000 - val_loss: 59194404.0000 - val_mse: 59194404.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 16s - loss: 77669048.0000 - mse: 77669048.0000 - val_loss: 59098676.0000 - val_mse: 59098676.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 20s - loss: 77399856.0000 - mse: 77399856.0000 - val_loss: 59281360.0000 - val_mse: 59281360.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 18s - loss: 77386880.0000 - mse: 77386880.0000 - val_loss: 73410656.0000 - val_mse: 73410656.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 18s - loss: 75847672.0000 - mse: 75847672.0000 - val_loss: 67988248.0000 - val_mse: 67988248.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 14s - loss: 75262960.0000 - mse: 75262960.0000 - val_loss: 59224296.0000 - val_mse: 59224296.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 14s - loss: 74539560.0000 - mse: 74539560.0000 - val_loss: 70068112.0000 - val_mse: 70068112.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 16s - loss: 74287552.0000 - mse: 74287552.0000 - val_loss: 58639864.0000 - val_mse: 58639864.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 17s - loss: 73923976.0000 - mse: 73923976.0000 - val_loss: 55544216.0000 - val_mse: 55544216.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 17s - loss: 74060040.0000 - mse: 74060040.0000 - val_loss: 58201692.0000 - val_mse: 58201692.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 17s - loss: 72295272.0000 - mse: 72295272.0000 - val_loss: 59850476.0000 - val_mse: 59850476.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 18s - loss: 72793432.0000 - mse: 72793432.0000 - val_loss: 66894032.0000 - val_mse: 66894032.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 19s - loss: 72214272.0000 - mse: 72214272.0000 - val_loss: 55475852.0000 - val_mse: 55475852.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 19s - loss: 72630984.0000 - mse: 72630984.0000 - val_loss: 55696116.0000 - val_mse: 55696116.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 17s - loss: 71761576.0000 - mse: 71761576.0000 - val_loss: 57840336.0000 - val_mse: 57840336.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 16s - loss: 71609256.0000 - mse: 71609256.0000 - val_loss: 59392024.0000 - val_mse: 59392024.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 18s - loss: 71389888.0000 - mse: 71389888.0000 - val_loss: 56876136.0000 - val_mse: 56876136.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 14s - loss: 71365704.0000 - mse: 71365704.0000 - val_loss: 65658136.0000 - val_mse: 65658136.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 15s - loss: 70511536.0000 - mse: 70511536.0000 - val_loss: 53460360.0000 - val_mse: 53460360.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 18s - loss: 71044488.0000 - mse: 71044488.0000 - val_loss: 65766312.0000 - val_mse: 65766312.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 15s - loss: 70935440.0000 - mse: 70935440.0000 - val_loss: 54621892.0000 - val_mse: 54621892.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 12s - loss: 69927336.0000 - mse: 69927336.0000 - val_loss: 57472932.0000 - val_mse: 57472932.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 12s - loss: 71458912.0000 - mse: 71458912.0000 - val_loss: 56559896.0000 - val_mse: 56559896.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 11s - loss: 70806264.0000 - mse: 70806264.0000 - val_loss: 56942492.0000 - val_mse: 56942492.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 12s - loss: 70108552.0000 - mse: 70108552.0000 - val_loss: 62161312.0000 - val_mse: 62161312.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 12s - loss: 71086248.0000 - mse: 71086248.0000 - val_loss: 54064872.0000 - val_mse: 54064872.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 12s - loss: 70598640.0000 - mse: 70598640.0000 - val_loss: 55395720.0000 - val_mse: 55395720.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 12s - loss: 70313304.0000 - mse: 70313304.0000 - val_loss: 58277672.0000 - val_mse: 58277672.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 11s - loss: 70323480.0000 - mse: 70323480.0000 - val_loss: 52813616.0000 - val_mse: 52813616.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 12s - loss: 70449424.0000 - mse: 70449424.0000 - val_loss: 65514608.0000 - val_mse: 65514608.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 12s - loss: 69728232.0000 - mse: 69728232.0000 - val_loss: 61051456.0000 - val_mse: 61051456.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 12s - loss: 69107936.0000 - mse: 69107936.0000 - val_loss: 55344192.0000 - val_mse: 55344192.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 11s - loss: 69704152.0000 - mse: 69704152.0000 - val_loss: 56968808.0000 - val_mse: 56968808.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 11s - loss: 71137504.0000 - mse: 71137504.0000 - val_loss: 57925696.0000 - val_mse: 57925696.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 12s - loss: 71335232.0000 - mse: 71335232.0000 - val_loss: 60686608.0000 - val_mse: 60686608.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 12s - loss: 71075728.0000 - mse: 71075728.0000 - val_loss: 69916120.0000 - val_mse: 69916120.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 11s - loss: 70860400.0000 - mse: 70860400.0000 - val_loss: 70998464.0000 - val_mse: 70998464.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 12s - loss: 71468704.0000 - mse: 71468704.0000 - val_loss: 52829308.0000 - val_mse: 52829308.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 11s - loss: 72358376.0000 - mse: 72358376.0000 - val_loss: 60580872.0000 - val_mse: 60580872.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 11s - loss: 71677440.0000 - mse: 71677440.0000 - val_loss: 57441348.0000 - val_mse: 57441348.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 11s - loss: 70083088.0000 - mse: 70083088.0000 - val_loss: 61159164.0000 - val_mse: 61159164.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 11s - loss: 71502928.0000 - mse: 71502928.0000 - val_loss: 63336348.0000 - val_mse: 63336348.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 11s - loss: 70928008.0000 - mse: 70928008.0000 - val_loss: 60777300.0000 - val_mse: 60777300.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 11s - loss: 70886976.0000 - mse: 70886976.0000 - val_loss: 54744112.0000 - val_mse: 54744112.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 11s - loss: 70968488.0000 - mse: 70968488.0000 - val_loss: 51889604.0000 - val_mse: 51889604.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 11s - loss: 70273712.0000 - mse: 70273712.0000 - val_loss: 56821532.0000 - val_mse: 56821532.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 12s - loss: 71476024.0000 - mse: 71476024.0000 - val_loss: 54243100.0000 - val_mse: 54243100.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 11s - loss: 71585992.0000 - mse: 71585992.0000 - val_loss: 52617828.0000 - val_mse: 52617828.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 12s - loss: 70540584.0000 - mse: 70540584.0000 - val_loss: 53106108.0000 - val_mse: 53106108.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 11s - loss: 70349136.0000 - mse: 70349136.0000 - val_loss: 63146040.0000 - val_mse: 63146040.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 11s - loss: 69468584.0000 - mse: 69468584.0000 - val_loss: 54792408.0000 - val_mse: 54792408.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 12s - loss: 68803400.0000 - mse: 68803400.0000 - val_loss: 59334164.0000 - val_mse: 59334164.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 12s - loss: 69339208.0000 - mse: 69339208.0000 - val_loss: 57241124.0000 - val_mse: 57241124.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 11s - loss: 69771024.0000 - mse: 69771024.0000 - val_loss: 52616660.0000 - val_mse: 52616660.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 11s - loss: 70536992.0000 - mse: 70536992.0000 - val_loss: 56545312.0000 - val_mse: 56545312.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 12s - loss: 70522504.0000 - mse: 70522504.0000 - val_loss: 59418988.0000 - val_mse: 59418988.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 11s - loss: 69043832.0000 - mse: 69043832.0000 - val_loss: 64200496.0000 - val_mse: 64200496.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 11s - loss: 70012088.0000 - mse: 70012088.0000 - val_loss: 59547468.0000 - val_mse: 59547468.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 11s - loss: 70284736.0000 - mse: 70284736.0000 - val_loss: 59700704.0000 - val_mse: 59700704.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 12s - loss: 69611736.0000 - mse: 69611736.0000 - val_loss: 57712196.0000 - val_mse: 57712196.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 11s - loss: 68190216.0000 - mse: 68190216.0000 - val_loss: 53225388.0000 - val_mse: 53225388.0000\n",
      "Epoch 63/1000\n",
      "6516/6516 - 11s - loss: 69712464.0000 - mse: 69712464.0000 - val_loss: 51942116.0000 - val_mse: 51942116.0000\n",
      "Epoch 64/1000\n",
      "6516/6516 - 11s - loss: 71759336.0000 - mse: 71759336.0000 - val_loss: 56564944.0000 - val_mse: 56564944.0000\n",
      "Epoch 65/1000\n",
      "6516/6516 - 12s - loss: 69546304.0000 - mse: 69546304.0000 - val_loss: 52414624.0000 - val_mse: 52414624.0000\n",
      "Epoch 66/1000\n",
      "6516/6516 - 12s - loss: 70429904.0000 - mse: 70429904.0000 - val_loss: 54077504.0000 - val_mse: 54077504.0000\n",
      "Epoch 67/1000\n",
      "6516/6516 - 14s - loss: 68821408.0000 - mse: 68821408.0000 - val_loss: 67528248.0000 - val_mse: 67528248.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "6516/6516 - 11s - loss: 69662880.0000 - mse: 69662880.0000 - val_loss: 54841464.0000 - val_mse: 54841464.0000\n",
      "Epoch 69/1000\n",
      "6516/6516 - 11s - loss: 70033888.0000 - mse: 70033888.0000 - val_loss: 52024228.0000 - val_mse: 52024228.0000\n",
      "Epoch 70/1000\n",
      "6516/6516 - 12s - loss: 69247504.0000 - mse: 69247504.0000 - val_loss: 55103728.0000 - val_mse: 55103728.0000\n",
      "Epoch 71/1000\n",
      "6516/6516 - 11s - loss: 69771528.0000 - mse: 69771528.0000 - val_loss: 55498884.0000 - val_mse: 55498884.0000\n",
      "Epoch 72/1000\n",
      "6516/6516 - 12s - loss: 68204640.0000 - mse: 68204640.0000 - val_loss: 60997200.0000 - val_mse: 60997200.0000\n",
      "Epoch 73/1000\n",
      "6516/6516 - 12s - loss: 71612944.0000 - mse: 71612944.0000 - val_loss: 54333228.0000 - val_mse: 54333228.0000\n",
      "Epoch 74/1000\n",
      "6516/6516 - 12s - loss: 70443472.0000 - mse: 70443472.0000 - val_loss: 53472296.0000 - val_mse: 53472296.0000\n",
      "Epoch 75/1000\n",
      "6516/6516 - 11s - loss: 71963024.0000 - mse: 71963024.0000 - val_loss: 57938772.0000 - val_mse: 57938772.0000\n",
      "Epoch 76/1000\n",
      "6516/6516 - 11s - loss: 69778784.0000 - mse: 69778784.0000 - val_loss: 55747108.0000 - val_mse: 55747108.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34132100569676316"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 14s - loss: 125396224.0000 - mse: 125396224.0000 - val_loss: 92729480.0000 - val_mse: 92729480.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 13s - loss: 250118192.0000 - mse: 250118192.0000 - val_loss: 91945136.0000 - val_mse: 91945136.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 13s - loss: 102807256.0000 - mse: 102807256.0000 - val_loss: 91565536.0000 - val_mse: 91565536.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 13s - loss: 115192032.0000 - mse: 115192032.0000 - val_loss: 92320544.0000 - val_mse: 92320544.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 13s - loss: 102741736.0000 - mse: 102741736.0000 - val_loss: 91600288.0000 - val_mse: 91600288.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 13s - loss: 102142448.0000 - mse: 102142448.0000 - val_loss: 91891616.0000 - val_mse: 91891616.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 13s - loss: 5319979008.0000 - mse: 5319979008.0000 - val_loss: 91782456.0000 - val_mse: 91782456.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 13s - loss: 102005624.0000 - mse: 102005624.0000 - val_loss: 91584208.0000 - val_mse: 91584208.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 13s - loss: 101867784.0000 - mse: 101867784.0000 - val_loss: 92956872.0000 - val_mse: 92956872.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 15s - loss: 101838456.0000 - mse: 101838456.0000 - val_loss: 91638240.0000 - val_mse: 91638240.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 13s - loss: 101804704.0000 - mse: 101804704.0000 - val_loss: 91707608.0000 - val_mse: 91707608.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 13s - loss: 101698920.0000 - mse: 101698920.0000 - val_loss: 91727528.0000 - val_mse: 91727528.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 13s - loss: 101572720.0000 - mse: 101572720.0000 - val_loss: 91906968.0000 - val_mse: 91906968.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 13s - loss: 101626656.0000 - mse: 101626656.0000 - val_loss: 91794800.0000 - val_mse: 91794800.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 13s - loss: 101550216.0000 - mse: 101550216.0000 - val_loss: 91828072.0000 - val_mse: 91828072.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 13s - loss: 106451560.0000 - mse: 106451560.0000 - val_loss: 91571552.0000 - val_mse: 91571552.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 13s - loss: 101440112.0000 - mse: 101440112.0000 - val_loss: 91592872.0000 - val_mse: 91592872.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 13s - loss: 101332880.0000 - mse: 101332880.0000 - val_loss: 91538296.0000 - val_mse: 91538296.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 13s - loss: 101351496.0000 - mse: 101351496.0000 - val_loss: 91458352.0000 - val_mse: 91458352.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 13s - loss: 101322440.0000 - mse: 101322440.0000 - val_loss: 92217616.0000 - val_mse: 92217616.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 13s - loss: 101260656.0000 - mse: 101260656.0000 - val_loss: 92306672.0000 - val_mse: 92306672.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 13s - loss: 101228056.0000 - mse: 101228056.0000 - val_loss: 91783256.0000 - val_mse: 91783256.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 13s - loss: 101198728.0000 - mse: 101198728.0000 - val_loss: 91553376.0000 - val_mse: 91553376.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 13s - loss: 101145504.0000 - mse: 101145504.0000 - val_loss: 91652728.0000 - val_mse: 91652728.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 13s - loss: 101099200.0000 - mse: 101099200.0000 - val_loss: 91678296.0000 - val_mse: 91678296.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 12s - loss: 101090200.0000 - mse: 101090200.0000 - val_loss: 91717960.0000 - val_mse: 91717960.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 12s - loss: 101018440.0000 - mse: 101018440.0000 - val_loss: 91695712.0000 - val_mse: 91695712.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 13s - loss: 101011168.0000 - mse: 101011168.0000 - val_loss: 91461944.0000 - val_mse: 91461944.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 13s - loss: 101005672.0000 - mse: 101005672.0000 - val_loss: 91961384.0000 - val_mse: 91961384.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 13s - loss: 100936336.0000 - mse: 100936336.0000 - val_loss: 91880488.0000 - val_mse: 91880488.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 13s - loss: 100929640.0000 - mse: 100929640.0000 - val_loss: 91619392.0000 - val_mse: 91619392.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 13s - loss: 100899784.0000 - mse: 100899784.0000 - val_loss: 91408160.0000 - val_mse: 91408160.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 13s - loss: 100891536.0000 - mse: 100891536.0000 - val_loss: 91945824.0000 - val_mse: 91945824.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 13s - loss: 100865432.0000 - mse: 100865432.0000 - val_loss: 91461176.0000 - val_mse: 91461176.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 13s - loss: 100800064.0000 - mse: 100800064.0000 - val_loss: 91878400.0000 - val_mse: 91878400.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 13s - loss: 100776216.0000 - mse: 100776216.0000 - val_loss: 92331568.0000 - val_mse: 92331568.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 13s - loss: 100733152.0000 - mse: 100733152.0000 - val_loss: 91541544.0000 - val_mse: 91541544.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 13s - loss: 100683008.0000 - mse: 100683008.0000 - val_loss: 91571400.0000 - val_mse: 91571400.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 13s - loss: 100791152.0000 - mse: 100791152.0000 - val_loss: 91613056.0000 - val_mse: 91613056.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 13s - loss: 100686944.0000 - mse: 100686944.0000 - val_loss: 91428224.0000 - val_mse: 91428224.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 12s - loss: 100640968.0000 - mse: 100640968.0000 - val_loss: 91833664.0000 - val_mse: 91833664.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 13s - loss: 100681312.0000 - mse: 100681312.0000 - val_loss: 91697368.0000 - val_mse: 91697368.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 12s - loss: 100708048.0000 - mse: 100708048.0000 - val_loss: 91465080.0000 - val_mse: 91465080.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 13s - loss: 100629880.0000 - mse: 100629880.0000 - val_loss: 91956312.0000 - val_mse: 91956312.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 13s - loss: 100663520.0000 - mse: 100663520.0000 - val_loss: 91480832.0000 - val_mse: 91480832.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 13s - loss: 100621632.0000 - mse: 100621632.0000 - val_loss: 91704192.0000 - val_mse: 91704192.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 13s - loss: 100603904.0000 - mse: 100603904.0000 - val_loss: 91833176.0000 - val_mse: 91833176.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 13s - loss: 100584304.0000 - mse: 100584304.0000 - val_loss: 91559768.0000 - val_mse: 91559768.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 13s - loss: 100605760.0000 - mse: 100605760.0000 - val_loss: 91682424.0000 - val_mse: 91682424.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 13s - loss: 100558288.0000 - mse: 100558288.0000 - val_loss: 91596368.0000 - val_mse: 91596368.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 13s - loss: 100560928.0000 - mse: 100560928.0000 - val_loss: 91973424.0000 - val_mse: 91973424.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 13s - loss: 100533664.0000 - mse: 100533664.0000 - val_loss: 91535944.0000 - val_mse: 91535944.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 13s - loss: 100573144.0000 - mse: 100573144.0000 - val_loss: 91608992.0000 - val_mse: 91608992.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 12s - loss: 100529320.0000 - mse: 100529320.0000 - val_loss: 91897840.0000 - val_mse: 91897840.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 13s - loss: 100523792.0000 - mse: 100523792.0000 - val_loss: 91564776.0000 - val_mse: 91564776.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 13s - loss: 100533944.0000 - mse: 100533944.0000 - val_loss: 91614984.0000 - val_mse: 91614984.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 13s - loss: 100475264.0000 - mse: 100475264.0000 - val_loss: 91501664.0000 - val_mse: 91501664.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 13s - loss: 100518264.0000 - mse: 100518264.0000 - val_loss: 91965104.0000 - val_mse: 91965104.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 13s - loss: 100470144.0000 - mse: 100470144.0000 - val_loss: 91429928.0000 - val_mse: 91429928.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 12s - loss: 100496088.0000 - mse: 100496088.0000 - val_loss: 91828328.0000 - val_mse: 91828328.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 12s - loss: 100494664.0000 - mse: 100494664.0000 - val_loss: 91479664.0000 - val_mse: 91479664.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 12s - loss: 100473392.0000 - mse: 100473392.0000 - val_loss: 91627880.0000 - val_mse: 91627880.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.3612678040917388e-06"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 14s - loss: 80642776.0000 - mse: 80642776.0000 - val_loss: 64524356.0000 - val_mse: 64524356.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 13s - loss: 77950808.0000 - mse: 77950808.0000 - val_loss: 74789088.0000 - val_mse: 74789088.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 13s - loss: 77016544.0000 - mse: 77016544.0000 - val_loss: 76102416.0000 - val_mse: 76102416.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 13s - loss: 76592192.0000 - mse: 76592192.0000 - val_loss: 72851520.0000 - val_mse: 72851520.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 13s - loss: 75350720.0000 - mse: 75350720.0000 - val_loss: 79249552.0000 - val_mse: 79249552.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 13s - loss: 75160352.0000 - mse: 75160352.0000 - val_loss: 91159056.0000 - val_mse: 91159056.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 13s - loss: 73575624.0000 - mse: 73575624.0000 - val_loss: 83958440.0000 - val_mse: 83958440.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 12s - loss: 72977624.0000 - mse: 72977624.0000 - val_loss: 80379272.0000 - val_mse: 80379272.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 13s - loss: 73149552.0000 - mse: 73149552.0000 - val_loss: 69643112.0000 - val_mse: 69643112.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 13s - loss: 72863464.0000 - mse: 72863464.0000 - val_loss: 87832168.0000 - val_mse: 87832168.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 13s - loss: 71521360.0000 - mse: 71521360.0000 - val_loss: 84742320.0000 - val_mse: 84742320.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 13s - loss: 71677696.0000 - mse: 71677696.0000 - val_loss: 87671208.0000 - val_mse: 87671208.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 13s - loss: 72625424.0000 - mse: 72625424.0000 - val_loss: 71382184.0000 - val_mse: 71382184.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 13s - loss: 72373704.0000 - mse: 72373704.0000 - val_loss: 92107368.0000 - val_mse: 92107368.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 13s - loss: 72440824.0000 - mse: 72440824.0000 - val_loss: 82999952.0000 - val_mse: 82999952.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 12s - loss: 72625032.0000 - mse: 72625032.0000 - val_loss: 73481200.0000 - val_mse: 73481200.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 13s - loss: 71988200.0000 - mse: 71988200.0000 - val_loss: 75785752.0000 - val_mse: 75785752.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 13s - loss: 71886144.0000 - mse: 71886144.0000 - val_loss: 74615504.0000 - val_mse: 74615504.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 13s - loss: 71949824.0000 - mse: 71949824.0000 - val_loss: 68105472.0000 - val_mse: 68105472.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 14s - loss: 72819200.0000 - mse: 72819200.0000 - val_loss: 58624804.0000 - val_mse: 58624804.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 16s - loss: 72242920.0000 - mse: 72242920.0000 - val_loss: 67831920.0000 - val_mse: 67831920.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 15s - loss: 72942624.0000 - mse: 72942624.0000 - val_loss: 63377704.0000 - val_mse: 63377704.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 13s - loss: 74211168.0000 - mse: 74211168.0000 - val_loss: 70919632.0000 - val_mse: 70919632.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 13s - loss: 73736232.0000 - mse: 73736232.0000 - val_loss: 69413240.0000 - val_mse: 69413240.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 13s - loss: 75236536.0000 - mse: 75236536.0000 - val_loss: 68397904.0000 - val_mse: 68397904.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 13s - loss: 73328584.0000 - mse: 73328584.0000 - val_loss: 72237272.0000 - val_mse: 72237272.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 13s - loss: 73179608.0000 - mse: 73179608.0000 - val_loss: 71770848.0000 - val_mse: 71770848.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 13s - loss: 74252264.0000 - mse: 74252264.0000 - val_loss: 77185384.0000 - val_mse: 77185384.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 13s - loss: 73620848.0000 - mse: 73620848.0000 - val_loss: 73544080.0000 - val_mse: 73544080.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 13s - loss: 75039136.0000 - mse: 75039136.0000 - val_loss: 68532976.0000 - val_mse: 68532976.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 13s - loss: 73593072.0000 - mse: 73593072.0000 - val_loss: 65074516.0000 - val_mse: 65074516.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 13s - loss: 73828840.0000 - mse: 73828840.0000 - val_loss: 70465784.0000 - val_mse: 70465784.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 13s - loss: 74992192.0000 - mse: 74992192.0000 - val_loss: 69949048.0000 - val_mse: 69949048.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 12s - loss: 74936472.0000 - mse: 74936472.0000 - val_loss: 68674624.0000 - val_mse: 68674624.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 13s - loss: 74857640.0000 - mse: 74857640.0000 - val_loss: 66428784.0000 - val_mse: 66428784.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 13s - loss: 76767744.0000 - mse: 76767744.0000 - val_loss: 64030212.0000 - val_mse: 64030212.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 13s - loss: 76709088.0000 - mse: 76709088.0000 - val_loss: 73698336.0000 - val_mse: 73698336.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 13s - loss: 74691184.0000 - mse: 74691184.0000 - val_loss: 78476024.0000 - val_mse: 78476024.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 13s - loss: 76760528.0000 - mse: 76760528.0000 - val_loss: 63593816.0000 - val_mse: 63593816.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 13s - loss: 77088640.0000 - mse: 77088640.0000 - val_loss: 63129124.0000 - val_mse: 63129124.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 13s - loss: 75464872.0000 - mse: 75464872.0000 - val_loss: 65399364.0000 - val_mse: 65399364.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 13s - loss: 75207408.0000 - mse: 75207408.0000 - val_loss: 61494108.0000 - val_mse: 61494108.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 13s - loss: 74435584.0000 - mse: 74435584.0000 - val_loss: 70024680.0000 - val_mse: 70024680.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 13s - loss: 74442256.0000 - mse: 74442256.0000 - val_loss: 64861200.0000 - val_mse: 64861200.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 13s - loss: 75682320.0000 - mse: 75682320.0000 - val_loss: 66569492.0000 - val_mse: 66569492.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 13s - loss: 73944528.0000 - mse: 73944528.0000 - val_loss: 68812400.0000 - val_mse: 68812400.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 13s - loss: 74746664.0000 - mse: 74746664.0000 - val_loss: 62013484.0000 - val_mse: 62013484.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 13s - loss: 75303080.0000 - mse: 75303080.0000 - val_loss: 58773684.0000 - val_mse: 58773684.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 13s - loss: 75710200.0000 - mse: 75710200.0000 - val_loss: 68760976.0000 - val_mse: 68760976.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 13s - loss: 74906240.0000 - mse: 74906240.0000 - val_loss: 71891368.0000 - val_mse: 71891368.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 39s - loss: 79043960.0000 - mse: 79043960.0000 - val_loss: 65650320.0000 - val_mse: 65650320.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 40s - loss: 72257272.0000 - mse: 72257272.0000 - val_loss: 62948668.0000 - val_mse: 62948668.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 52s - loss: 70432632.0000 - mse: 70432632.0000 - val_loss: 60221132.0000 - val_mse: 60221132.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 38s - loss: 69183752.0000 - mse: 69183752.0000 - val_loss: 60662448.0000 - val_mse: 60662448.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 32s - loss: 68873552.0000 - mse: 68873552.0000 - val_loss: 60258288.0000 - val_mse: 60258288.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 29s - loss: 68279120.0000 - mse: 68279120.0000 - val_loss: 60227296.0000 - val_mse: 60227296.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 30s - loss: 67817360.0000 - mse: 67817360.0000 - val_loss: 60400684.0000 - val_mse: 60400684.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 32s - loss: 67378448.0000 - mse: 67378448.0000 - val_loss: 59092820.0000 - val_mse: 59092820.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 37s - loss: 67221072.0000 - mse: 67221072.0000 - val_loss: 58421864.0000 - val_mse: 58421864.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 40s - loss: 66984408.0000 - mse: 66984408.0000 - val_loss: 58668504.0000 - val_mse: 58668504.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 26s - loss: 66678416.0000 - mse: 66678416.0000 - val_loss: 59480640.0000 - val_mse: 59480640.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 25s - loss: 66357968.0000 - mse: 66357968.0000 - val_loss: 58479472.0000 - val_mse: 58479472.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 25s - loss: 66349396.0000 - mse: 66349396.0000 - val_loss: 57538620.0000 - val_mse: 57538620.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 25s - loss: 66337212.0000 - mse: 66337212.0000 - val_loss: 57309872.0000 - val_mse: 57309872.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 25s - loss: 66337228.0000 - mse: 66337228.0000 - val_loss: 57157296.0000 - val_mse: 57157296.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 26s - loss: 66510280.0000 - mse: 66510280.0000 - val_loss: 57597756.0000 - val_mse: 57597756.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 26s - loss: 66298464.0000 - mse: 66298464.0000 - val_loss: 56668576.0000 - val_mse: 56668576.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 26s - loss: 66242180.0000 - mse: 66242180.0000 - val_loss: 60008584.0000 - val_mse: 60008584.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 26s - loss: 66434608.0000 - mse: 66434608.0000 - val_loss: 57989404.0000 - val_mse: 57989404.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 27s - loss: 66146232.0000 - mse: 66146232.0000 - val_loss: 56601776.0000 - val_mse: 56601776.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 31s - loss: 66411492.0000 - mse: 66411492.0000 - val_loss: 60311876.0000 - val_mse: 60311876.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 30s - loss: 66361108.0000 - mse: 66361108.0000 - val_loss: 58922816.0000 - val_mse: 58922816.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 28s - loss: 65966396.0000 - mse: 65966396.0000 - val_loss: 59301624.0000 - val_mse: 59301624.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 26s - loss: 66199868.0000 - mse: 66199868.0000 - val_loss: 62219212.0000 - val_mse: 62219212.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 25s - loss: 66605752.0000 - mse: 66605752.0000 - val_loss: 60504688.0000 - val_mse: 60504688.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 26s - loss: 66854944.0000 - mse: 66854944.0000 - val_loss: 61264008.0000 - val_mse: 61264008.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 25s - loss: 66588388.0000 - mse: 66588388.0000 - val_loss: 62030724.0000 - val_mse: 62030724.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 26s - loss: 66905492.0000 - mse: 66905492.0000 - val_loss: 62224156.0000 - val_mse: 62224156.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 25s - loss: 66671084.0000 - mse: 66671084.0000 - val_loss: 63215872.0000 - val_mse: 63215872.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 25s - loss: 66731260.0000 - mse: 66731260.0000 - val_loss: 58349628.0000 - val_mse: 58349628.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 25s - loss: 66903696.0000 - mse: 66903696.0000 - val_loss: 64150444.0000 - val_mse: 64150444.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 26s - loss: 66873056.0000 - mse: 66873056.0000 - val_loss: 60863260.0000 - val_mse: 60863260.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 25s - loss: 66818568.0000 - mse: 66818568.0000 - val_loss: 60483372.0000 - val_mse: 60483372.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 26s - loss: 66792660.0000 - mse: 66792660.0000 - val_loss: 61107208.0000 - val_mse: 61107208.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 26s - loss: 67046664.0000 - mse: 67046664.0000 - val_loss: 63376588.0000 - val_mse: 63376588.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 26s - loss: 67385464.0000 - mse: 67385464.0000 - val_loss: 65370576.0000 - val_mse: 65370576.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 26s - loss: 67150480.0000 - mse: 67150480.0000 - val_loss: 62132196.0000 - val_mse: 62132196.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 25s - loss: 67200520.0000 - mse: 67200520.0000 - val_loss: 61658520.0000 - val_mse: 61658520.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 25s - loss: 67488880.0000 - mse: 67488880.0000 - val_loss: 61819904.0000 - val_mse: 61819904.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 26s - loss: 67358176.0000 - mse: 67358176.0000 - val_loss: 62713396.0000 - val_mse: 62713396.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 25s - loss: 67175232.0000 - mse: 67175232.0000 - val_loss: 63000300.0000 - val_mse: 63000300.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 25s - loss: 67620176.0000 - mse: 67620176.0000 - val_loss: 66163036.0000 - val_mse: 66163036.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 26s - loss: 67696376.0000 - mse: 67696376.0000 - val_loss: 60227556.0000 - val_mse: 60227556.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 25s - loss: 67550944.0000 - mse: 67550944.0000 - val_loss: 61745628.0000 - val_mse: 61745628.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 26s - loss: 67565240.0000 - mse: 67565240.0000 - val_loss: 60841384.0000 - val_mse: 60841384.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 25s - loss: 68092360.0000 - mse: 68092360.0000 - val_loss: 60750540.0000 - val_mse: 60750540.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 25s - loss: 68286688.0000 - mse: 68286688.0000 - val_loss: 62628908.0000 - val_mse: 62628908.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 25s - loss: 67881656.0000 - mse: 67881656.0000 - val_loss: 63218352.0000 - val_mse: 63218352.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 26s - loss: 67931792.0000 - mse: 67931792.0000 - val_loss: 62063968.0000 - val_mse: 62063968.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 25s - loss: 67927680.0000 - mse: 67927680.0000 - val_loss: 63554632.0000 - val_mse: 63554632.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(258, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29200721629590554"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6516/6516 - 27s - loss: 72537576.0000 - mse: 72537576.0000 - val_loss: 61350320.0000 - val_mse: 61350320.0000\n",
      "Epoch 2/1000\n",
      "6516/6516 - 25s - loss: 69416424.0000 - mse: 69416424.0000 - val_loss: 60871360.0000 - val_mse: 60871360.0000\n",
      "Epoch 3/1000\n",
      "6516/6516 - 26s - loss: 67815232.0000 - mse: 67815232.0000 - val_loss: 59955976.0000 - val_mse: 59955976.0000\n",
      "Epoch 4/1000\n",
      "6516/6516 - 25s - loss: 68222624.0000 - mse: 68222624.0000 - val_loss: 63156688.0000 - val_mse: 63156688.0000\n",
      "Epoch 5/1000\n",
      "6516/6516 - 25s - loss: 68241464.0000 - mse: 68241464.0000 - val_loss: 64867840.0000 - val_mse: 64867840.0000\n",
      "Epoch 6/1000\n",
      "6516/6516 - 25s - loss: 67845352.0000 - mse: 67845352.0000 - val_loss: 61266980.0000 - val_mse: 61266980.0000\n",
      "Epoch 7/1000\n",
      "6516/6516 - 25s - loss: 67418512.0000 - mse: 67418512.0000 - val_loss: 60493600.0000 - val_mse: 60493600.0000\n",
      "Epoch 8/1000\n",
      "6516/6516 - 26s - loss: 67456152.0000 - mse: 67456152.0000 - val_loss: 61262768.0000 - val_mse: 61262768.0000\n",
      "Epoch 9/1000\n",
      "6516/6516 - 25s - loss: 67409776.0000 - mse: 67409776.0000 - val_loss: 55332704.0000 - val_mse: 55332704.0000\n",
      "Epoch 10/1000\n",
      "6516/6516 - 26s - loss: 66550988.0000 - mse: 66550988.0000 - val_loss: 57524296.0000 - val_mse: 57524296.0000\n",
      "Epoch 11/1000\n",
      "6516/6516 - 26s - loss: 66592640.0000 - mse: 66592640.0000 - val_loss: 61945536.0000 - val_mse: 61945536.0000\n",
      "Epoch 12/1000\n",
      "6516/6516 - 26s - loss: 66020300.0000 - mse: 66020300.0000 - val_loss: 58128040.0000 - val_mse: 58128040.0000\n",
      "Epoch 13/1000\n",
      "6516/6516 - 26s - loss: 66455596.0000 - mse: 66455596.0000 - val_loss: 59980112.0000 - val_mse: 59980112.0000\n",
      "Epoch 14/1000\n",
      "6516/6516 - 25s - loss: 66167084.0000 - mse: 66167084.0000 - val_loss: 56314456.0000 - val_mse: 56314456.0000\n",
      "Epoch 15/1000\n",
      "6516/6516 - 26s - loss: 66059660.0000 - mse: 66059660.0000 - val_loss: 59090848.0000 - val_mse: 59090848.0000\n",
      "Epoch 16/1000\n",
      "6516/6516 - 26s - loss: 65872512.0000 - mse: 65872512.0000 - val_loss: 56868092.0000 - val_mse: 56868092.0000\n",
      "Epoch 17/1000\n",
      "6516/6516 - 25s - loss: 65464536.0000 - mse: 65464536.0000 - val_loss: 56800516.0000 - val_mse: 56800516.0000\n",
      "Epoch 18/1000\n",
      "6516/6516 - 25s - loss: 65064424.0000 - mse: 65064424.0000 - val_loss: 54561756.0000 - val_mse: 54561756.0000\n",
      "Epoch 19/1000\n",
      "6516/6516 - 25s - loss: 64537276.0000 - mse: 64537276.0000 - val_loss: 58595944.0000 - val_mse: 58595944.0000\n",
      "Epoch 20/1000\n",
      "6516/6516 - 25s - loss: 65990544.0000 - mse: 65990544.0000 - val_loss: 57924052.0000 - val_mse: 57924052.0000\n",
      "Epoch 21/1000\n",
      "6516/6516 - 26s - loss: 65870464.0000 - mse: 65870464.0000 - val_loss: 54468848.0000 - val_mse: 54468848.0000\n",
      "Epoch 22/1000\n",
      "6516/6516 - 26s - loss: 65679932.0000 - mse: 65679932.0000 - val_loss: 56527184.0000 - val_mse: 56527184.0000\n",
      "Epoch 23/1000\n",
      "6516/6516 - 25s - loss: 65031404.0000 - mse: 65031404.0000 - val_loss: 57395248.0000 - val_mse: 57395248.0000\n",
      "Epoch 24/1000\n",
      "6516/6516 - 25s - loss: 65846208.0000 - mse: 65846208.0000 - val_loss: 56561172.0000 - val_mse: 56561172.0000\n",
      "Epoch 25/1000\n",
      "6516/6516 - 25s - loss: 66008372.0000 - mse: 66008372.0000 - val_loss: 55505204.0000 - val_mse: 55505204.0000\n",
      "Epoch 26/1000\n",
      "6516/6516 - 26s - loss: 65080140.0000 - mse: 65080140.0000 - val_loss: 58369836.0000 - val_mse: 58369836.0000\n",
      "Epoch 27/1000\n",
      "6516/6516 - 26s - loss: 65711216.0000 - mse: 65711216.0000 - val_loss: 55084700.0000 - val_mse: 55084700.0000\n",
      "Epoch 28/1000\n",
      "6516/6516 - 25s - loss: 65700908.0000 - mse: 65700908.0000 - val_loss: 56175976.0000 - val_mse: 56175976.0000\n",
      "Epoch 29/1000\n",
      "6516/6516 - 28s - loss: 65882424.0000 - mse: 65882424.0000 - val_loss: 55324344.0000 - val_mse: 55324344.0000\n",
      "Epoch 30/1000\n",
      "6516/6516 - 25s - loss: 65909192.0000 - mse: 65909192.0000 - val_loss: 55771876.0000 - val_mse: 55771876.0000\n",
      "Epoch 31/1000\n",
      "6516/6516 - 25s - loss: 65825428.0000 - mse: 65825428.0000 - val_loss: 58078652.0000 - val_mse: 58078652.0000\n",
      "Epoch 32/1000\n",
      "6516/6516 - 25s - loss: 65985496.0000 - mse: 65985496.0000 - val_loss: 54741904.0000 - val_mse: 54741904.0000\n",
      "Epoch 33/1000\n",
      "6516/6516 - 26s - loss: 65496016.0000 - mse: 65496016.0000 - val_loss: 58760656.0000 - val_mse: 58760656.0000\n",
      "Epoch 34/1000\n",
      "6516/6516 - 25s - loss: 65305736.0000 - mse: 65305736.0000 - val_loss: 57464868.0000 - val_mse: 57464868.0000\n",
      "Epoch 35/1000\n",
      "6516/6516 - 25s - loss: 65335904.0000 - mse: 65335904.0000 - val_loss: 56171900.0000 - val_mse: 56171900.0000\n",
      "Epoch 36/1000\n",
      "6516/6516 - 25s - loss: 64834628.0000 - mse: 64834628.0000 - val_loss: 56351368.0000 - val_mse: 56351368.0000\n",
      "Epoch 37/1000\n",
      "6516/6516 - 26s - loss: 65503124.0000 - mse: 65503124.0000 - val_loss: 56756364.0000 - val_mse: 56756364.0000\n",
      "Epoch 38/1000\n",
      "6516/6516 - 25s - loss: 65164996.0000 - mse: 65164996.0000 - val_loss: 57161568.0000 - val_mse: 57161568.0000\n",
      "Epoch 39/1000\n",
      "6516/6516 - 25s - loss: 65255656.0000 - mse: 65255656.0000 - val_loss: 55734296.0000 - val_mse: 55734296.0000\n",
      "Epoch 40/1000\n",
      "6516/6516 - 25s - loss: 65375092.0000 - mse: 65375092.0000 - val_loss: 55710336.0000 - val_mse: 55710336.0000\n",
      "Epoch 41/1000\n",
      "6516/6516 - 26s - loss: 65687352.0000 - mse: 65687352.0000 - val_loss: 54112300.0000 - val_mse: 54112300.0000\n",
      "Epoch 42/1000\n",
      "6516/6516 - 26s - loss: 67154512.0000 - mse: 67154512.0000 - val_loss: 57932548.0000 - val_mse: 57932548.0000\n",
      "Epoch 43/1000\n",
      "6516/6516 - 25s - loss: 65421112.0000 - mse: 65421112.0000 - val_loss: 58284424.0000 - val_mse: 58284424.0000\n",
      "Epoch 44/1000\n",
      "6516/6516 - 26s - loss: 65461960.0000 - mse: 65461960.0000 - val_loss: 55438772.0000 - val_mse: 55438772.0000\n",
      "Epoch 45/1000\n",
      "6516/6516 - 25s - loss: 65633908.0000 - mse: 65633908.0000 - val_loss: 55040356.0000 - val_mse: 55040356.0000\n",
      "Epoch 46/1000\n",
      "6516/6516 - 26s - loss: 66074336.0000 - mse: 66074336.0000 - val_loss: 56876068.0000 - val_mse: 56876068.0000\n",
      "Epoch 47/1000\n",
      "6516/6516 - 26s - loss: 65559448.0000 - mse: 65559448.0000 - val_loss: 53373500.0000 - val_mse: 53373500.0000\n",
      "Epoch 48/1000\n",
      "6516/6516 - 25s - loss: 65708240.0000 - mse: 65708240.0000 - val_loss: 55970564.0000 - val_mse: 55970564.0000\n",
      "Epoch 49/1000\n",
      "6516/6516 - 25s - loss: 66966968.0000 - mse: 66966968.0000 - val_loss: 56278468.0000 - val_mse: 56278468.0000\n",
      "Epoch 50/1000\n",
      "6516/6516 - 25s - loss: 65770196.0000 - mse: 65770196.0000 - val_loss: 58725828.0000 - val_mse: 58725828.0000\n",
      "Epoch 51/1000\n",
      "6516/6516 - 25s - loss: 66484544.0000 - mse: 66484544.0000 - val_loss: 53163156.0000 - val_mse: 53163156.0000\n",
      "Epoch 52/1000\n",
      "6516/6516 - 26s - loss: 67773352.0000 - mse: 67773352.0000 - val_loss: 59471840.0000 - val_mse: 59471840.0000\n",
      "Epoch 53/1000\n",
      "6516/6516 - 25s - loss: 66063460.0000 - mse: 66063460.0000 - val_loss: 56949228.0000 - val_mse: 56949228.0000\n",
      "Epoch 54/1000\n",
      "6516/6516 - 25s - loss: 65502784.0000 - mse: 65502784.0000 - val_loss: 56309896.0000 - val_mse: 56309896.0000\n",
      "Epoch 55/1000\n",
      "6516/6516 - 26s - loss: 65743772.0000 - mse: 65743772.0000 - val_loss: 56485576.0000 - val_mse: 56485576.0000\n",
      "Epoch 56/1000\n",
      "6516/6516 - 25s - loss: 74272568.0000 - mse: 74272568.0000 - val_loss: 56346360.0000 - val_mse: 56346360.0000\n",
      "Epoch 57/1000\n",
      "6516/6516 - 25s - loss: 64567944.0000 - mse: 64567944.0000 - val_loss: 57794860.0000 - val_mse: 57794860.0000\n",
      "Epoch 58/1000\n",
      "6516/6516 - 25s - loss: 66853556.0000 - mse: 66853556.0000 - val_loss: 56630996.0000 - val_mse: 56630996.0000\n",
      "Epoch 59/1000\n",
      "6516/6516 - 25s - loss: 65528852.0000 - mse: 65528852.0000 - val_loss: 55939804.0000 - val_mse: 55939804.0000\n",
      "Epoch 60/1000\n",
      "6516/6516 - 26s - loss: 66278884.0000 - mse: 66278884.0000 - val_loss: 53841984.0000 - val_mse: 53841984.0000\n",
      "Epoch 61/1000\n",
      "6516/6516 - 25s - loss: 66323200.0000 - mse: 66323200.0000 - val_loss: 59394516.0000 - val_mse: 59394516.0000\n",
      "Epoch 62/1000\n",
      "6516/6516 - 25s - loss: 66813044.0000 - mse: 66813044.0000 - val_loss: 55681972.0000 - val_mse: 55681972.0000\n",
      "Epoch 63/1000\n",
      "6516/6516 - 25s - loss: 65989648.0000 - mse: 65989648.0000 - val_loss: 57771352.0000 - val_mse: 57771352.0000\n",
      "Epoch 64/1000\n",
      "6516/6516 - 25s - loss: 65841908.0000 - mse: 65841908.0000 - val_loss: 56859552.0000 - val_mse: 56859552.0000\n",
      "Epoch 65/1000\n",
      "6516/6516 - 26s - loss: 66229836.0000 - mse: 66229836.0000 - val_loss: 54998020.0000 - val_mse: 54998020.0000\n",
      "Epoch 66/1000\n",
      "6516/6516 - 25s - loss: 66365768.0000 - mse: 66365768.0000 - val_loss: 56562444.0000 - val_mse: 56562444.0000\n",
      "Epoch 67/1000\n",
      "6516/6516 - 25s - loss: 69276400.0000 - mse: 69276400.0000 - val_loss: 57859912.0000 - val_mse: 57859912.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "6516/6516 - 25s - loss: 68905408.0000 - mse: 68905408.0000 - val_loss: 58171184.0000 - val_mse: 58171184.0000\n",
      "Epoch 69/1000\n",
      "6516/6516 - 26s - loss: 66512856.0000 - mse: 66512856.0000 - val_loss: 54682696.0000 - val_mse: 54682696.0000\n",
      "Epoch 70/1000\n",
      "6516/6516 - 26s - loss: 67041272.0000 - mse: 67041272.0000 - val_loss: 55455756.0000 - val_mse: 55455756.0000\n",
      "Epoch 71/1000\n",
      "6516/6516 - 25s - loss: 65750604.0000 - mse: 65750604.0000 - val_loss: 55978588.0000 - val_mse: 55978588.0000\n",
      "Epoch 72/1000\n",
      "6516/6516 - 26s - loss: 67121192.0000 - mse: 67121192.0000 - val_loss: 56800768.0000 - val_mse: 56800768.0000\n",
      "Epoch 73/1000\n",
      "6516/6516 - 25s - loss: 66656396.0000 - mse: 66656396.0000 - val_loss: 58241776.0000 - val_mse: 58241776.0000\n",
      "Epoch 74/1000\n",
      "6516/6516 - 25s - loss: 65971936.0000 - mse: 65971936.0000 - val_loss: 56365712.0000 - val_mse: 56365712.0000\n",
      "Epoch 75/1000\n",
      "6516/6516 - 25s - loss: 66496168.0000 - mse: 66496168.0000 - val_loss: 55835456.0000 - val_mse: 55835456.0000\n",
      "Epoch 76/1000\n",
      "6516/6516 - 25s - loss: 66052132.0000 - mse: 66052132.0000 - val_loss: 56846376.0000 - val_mse: 56846376.0000\n",
      "Epoch 77/1000\n",
      "6516/6516 - 25s - loss: 66813288.0000 - mse: 66813288.0000 - val_loss: 58097440.0000 - val_mse: 58097440.0000\n",
      "Epoch 78/1000\n",
      "6516/6516 - 26s - loss: 66810012.0000 - mse: 66810012.0000 - val_loss: 56461220.0000 - val_mse: 56461220.0000\n",
      "Epoch 79/1000\n",
      "6516/6516 - 25s - loss: 74941424.0000 - mse: 74941424.0000 - val_loss: 57429672.0000 - val_mse: 57429672.0000\n",
      "Epoch 80/1000\n",
      "6516/6516 - 25s - loss: 67233688.0000 - mse: 67233688.0000 - val_loss: 57809632.0000 - val_mse: 57809632.0000\n",
      "Epoch 81/1000\n",
      "6516/6516 - 25s - loss: 66527224.0000 - mse: 66527224.0000 - val_loss: 55489812.0000 - val_mse: 55489812.0000\n"
     ]
    }
   ],
   "source": [
    "# tweaking model parameters\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          input_shape=(X_train.shape[1], )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(258, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, clipnorm = 1)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = model.fit(\n",
    "  X_train.values, y_train_new.values,\n",
    "  epochs=EPOCHS, validation_split=0.2, verbose = 2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3275051313854723"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test set\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "r2_score(y_test, predictions * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, best Random Forest score was over 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
